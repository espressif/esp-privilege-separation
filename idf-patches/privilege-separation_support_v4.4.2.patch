diff --git a/components/app_update/esp_ota_ops.c b/components/app_update/esp_ota_ops.c
index c81dff19f8..0fe6e0efd7 100644
--- a/components/app_update/esp_ota_ops.c
+++ b/components/app_update/esp_ota_ops.c
@@ -56,8 +56,10 @@ static bool is_ota_partition(const esp_partition_t *p)
 {
     return (p != NULL
             && p->type == ESP_PARTITION_TYPE_APP
-            && p->subtype >= ESP_PARTITION_SUBTYPE_APP_OTA_0
-            && p->subtype < ESP_PARTITION_SUBTYPE_APP_OTA_MAX);
+            && ((p->subtype >= ESP_PARTITION_SUBTYPE_APP_OTA_0
+            && p->subtype < ESP_PARTITION_SUBTYPE_APP_OTA_MAX)
+            || (p->subtype >= ESP_PARTITION_SUBTYPE_APP_USER_0
+            && p->subtype <= ESP_PARTITION_SUBTYPE_APP_USER_1)));
 }
 
 // Read otadata partition and fill array from two otadata structures.
diff --git a/components/esp32c3/Kconfig b/components/esp32c3/Kconfig
index 5c7c072c46..705336cfd3 100644
--- a/components/esp32c3/Kconfig
+++ b/components/esp32c3/Kconfig
@@ -187,4 +187,14 @@ menu "ESP32C3-Specific"
             If enabled, this disables the linking of binary libraries in the application build. Note
             that after enabling this Wi-Fi/Bluetooth will not work.
 
+    config ESP_PRIVILEGE_SEPARATION_ENABLE
+        bool "Enable privilege separation using WORLD controller"
+        default n
+        select FREERTOS_SUPPORT_STATIC_ALLOCATION
+        select FREERTOS_ENABLE_STATIC_TASK_CLEAN_UP
+        select FREERTOS_PLACE_FUNCTIONS_INTO_FLASH
+        select NEWLIB_NANO_FORMAT
+        help
+            Enable user kernel separation
+
 endmenu  # ESP32C3-Specific
diff --git a/components/esp32s3/Kconfig b/components/esp32s3/Kconfig
index 07dd0a32be..1326a660dd 100644
--- a/components/esp32s3/Kconfig
+++ b/components/esp32s3/Kconfig
@@ -515,4 +515,14 @@ menu "ESP32S3-Specific"
         help
             RAM size dedicated for static variables (.data & .bss sections).
 
+    config ESP_PRIVILEGE_SEPARATION_ENABLE
+        bool "Enable privilege separation using WORLD controller"
+        default n
+        select FREERTOS_SUPPORT_STATIC_ALLOCATION
+        select FREERTOS_ENABLE_STATIC_TASK_CLEAN_UP
+        select FREERTOS_PLACE_FUNCTIONS_INTO_FLASH
+        select NEWLIB_NANO_FORMAT
+        help
+            Enable user kernel separation
+
 endmenu  # ESP32S3-Specific
diff --git a/components/esp_system/Kconfig b/components/esp_system/Kconfig
index 5cdab58bf0..a1a72498d8 100644
--- a/components/esp_system/Kconfig
+++ b/components/esp_system/Kconfig
@@ -113,6 +113,7 @@ menu "ESP System Settings"
             bool
             default y if IDF_TARGET_ESP32S2
             default y if IDF_TARGET_ESP32C3
+            default y if IDF_TARGET_ESP32S3 && ESP_PRIVILEGE_SEPARATION_ENABLE
             default y if IDF_TARGET_ESP32H2
 
         config ESP_SYSTEM_MEMPROT_FEATURE
diff --git a/components/esp_system/ld/esp32c3/sections.ld.in b/components/esp_system/ld/esp32c3/sections.ld.in
index 9458dc39c3..0b8944e9ee 100644
--- a/components/esp_system/ld/esp32c3/sections.ld.in
+++ b/components/esp_system/ld/esp32c3/sections.ld.in
@@ -4,6 +4,16 @@
  * SPDX-License-Identifier: Apache-2.0
  */
 
+#include "sdkconfig.h"
+
+/* DRAM region from 0x3FCDF060 is reserved for ROM functions
+ * and user app should not be able to access it. A split line
+ * is added to protect reserved ROM region. As the split line
+ * can only be added at 256 byte aligned address, alignment
+ * correction is used here.
+ */
+#define ROM_DRAM_RESERVE_START          ((0x3FCDF060) & ~((256) - 1))
+
 /* Default entry point */
 ENTRY(call_start_cpu0);
 
@@ -122,6 +132,13 @@ SECTIONS
   .iram0.text :
   {
     _iram_start = ABSOLUTE(.);
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    _reserve_w1_iram_start = ABSOLUTE(.);
+    . += CONFIG_PA_ALLOCATE_USER_IRAM_SIZE;
+    . += 16;
+    . = ALIGN (0x200);
+    _reserve_w1_iram_end = ABSOLUTE(.);
+#endif
     /* Vectors go to start of IRAM */
     ASSERT(ABSOLUTE(.) % 0x100 == 0, "vector address must be 256 byte aligned");
     KEEP(*(.exception_vectors.text));
@@ -206,6 +223,27 @@ SECTIONS
     _bss_end = ABSOLUTE(.);
   } > dram0_0_seg
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+  .reserve_w1_dram (NOLOAD) :
+  {
+     /* Assign W1 DRAM start address as per the size configured in Kconfig.
+      * 0x3FCDF060 - 0x3FCE0000 space is reserved for ROM code so to avoid
+      * overlapping for reserved memory regions, treat 0x3FCDF060 as the end of DRAM region
+      */
+#if CONFIG_PA_MEMORY_ALLOCATE_PROTECTED
+     _reserve_w1_dram_start = ABSOLUTE(_data_start + CONFIG_PA_ALLOCATE_DRAM_SIZE);
+#elif CONFIG_PA_MEMORY_ALLOCATE_USER
+     _reserve_w1_dram_start = ABSOLUTE(ROM_DRAM_RESERVE_START - CONFIG_PA_ALLOCATE_DRAM_SIZE);
+#endif
+     /* Align the starting boundary to 512 bytes as it is a requirement for the PMS split line */
+     _reserve_w1_dram_start = ABSOLUTE((_reserve_w1_dram_start + 0x200 - 1) & ~(0x200 - 1));
+     _reserve_w1_dram_end = ABSOLUTE(ROM_DRAM_RESERVE_START);
+  } > dram0_0_seg
+
+  ASSERT((_heap_start <= _reserve_w1_dram_start),
+          "Protected DRAM segment contents does not fit.")
+#endif
+
   ASSERT(((_bss_end - ORIGIN(dram0_0_seg)) <= LENGTH(dram0_0_seg)), "DRAM segment data does not fit.")
 
   .flash.text :
diff --git a/components/esp_system/ld/esp32s3/sections.ld.in b/components/esp_system/ld/esp32s3/sections.ld.in
index e8b7489335..6e27432995 100644
--- a/components/esp_system/ld/esp32s3/sections.ld.in
+++ b/components/esp_system/ld/esp32s3/sections.ld.in
@@ -4,6 +4,16 @@
  * SPDX-License-Identifier: Apache-2.0
  */
 
+#include "sdkconfig.h"
+
+/* DRAM region from 0x3FCEEE34 is reserved for ROM functions
+ * and user app should not be able to access it. A split line
+ * is added to protect reserved ROM region. As the split line
+ * can only be added at 256 byte aligned address, alignment
+ * correction is used here.
+ */
+#define ROM_DRAM_RESERVE_START          ((0x3FCEEE34) & ~((256) - 1))
+
 /* Default entry point */
 ENTRY(call_start_cpu0);
 
@@ -131,10 +141,34 @@ SECTIONS
   ASSERT((_rtc_fast_length <= LENGTH(rtc_data_seg)),
           "RTC_FAST segment data does not fit.")
 
+  .iram0.user_iram :
+  {
+    _iram_start = ABSOLUTE(.);
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    _reserve_w1_iram_start = ABSOLUTE(.);
+    . += CONFIG_PA_ALLOCATE_USER_IRAM_SIZE;
+    . += 16;
+    /* This alignment is the requirement of WORLD controller vecbase register.
+     * The vector table should be aligned at 1024 boundary.
+     * As the WORLD0 vector table will start right after this section,
+     * it has to be aligned at 1024 bytes.
+     */
+    . = ALIGN (0x400);
+    _reserve_w1_iram_end = ABSOLUTE(.);
+#if CONFIG_ESP32S3_INSTRUCTION_CACHE_16KB
+    /* In case the instruction cache size is 16KB, the other 16KB block will be used as IRAM.
+     * There is a single permission block for this 16KB memory, so we allocate it entirely to
+     * WORLD1.
+     */
+    . = ABSOLUTE(0x40378000);
+    _reserve_w1_iram_end = ABSOLUTE(.);
+#endif
+#endif
+  } > iram0_0_seg
+
   /* Send .iram0 code to iram */
   .iram0.vectors :
   {
-    _iram_start = ABSOLUTE(.);
     /* Vectors go to IRAM */
     _vector_table = ABSOLUTE(.);
     . = 0x0;
@@ -249,6 +283,27 @@ SECTIONS
     _bss_end = ABSOLUTE(.);
   } > dram0_0_seg
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+  .reserve_w1_dram (NOLOAD) :
+  {
+     /* Assign W1 DRAM start address as per the size configured in Kconfig.
+      * 0x3FCEEE34 - 0x3FCF0000 space is reserved for ROM code so to avoid
+      * overlapping for reserved memory regions, treat 0x3FCEEE34 as the end of DRAM region
+      */
+#if CONFIG_PA_MEMORY_ALLOCATE_PROTECTED
+     _reserve_w1_dram_start = ABSOLUTE(_data_start + CONFIG_PA_ALLOCATE_DRAM_SIZE);
+#elif CONFIG_PA_MEMORY_ALLOCATE_USER
+     _reserve_w1_dram_start = ABSOLUTE(ROM_DRAM_RESERVE_START - CONFIG_PA_ALLOCATE_DRAM_SIZE);
+#endif
+     /* Align the starting boundary to 512 bytes as it is a requirement for the PMS split line */
+     _reserve_w1_dram_start = ABSOLUTE((_reserve_w1_dram_start + 0x200 - 1) & ~(0x200 - 1));
+     _reserve_w1_dram_end = ABSOLUTE(ROM_DRAM_RESERVE_START);
+  } > dram0_0_seg
+
+  ASSERT((_heap_start <= _reserve_w1_dram_start),
+          "Protected DRAM segment contents does not fit.")
+#endif
+
   ASSERT(((_bss_end - ORIGIN(dram0_0_seg)) <= LENGTH(dram0_0_seg)), "DRAM segment data does not fit.")
 
   .flash.text :
diff --git a/components/esp_system/ld/ld.cmake b/components/esp_system/ld/ld.cmake
index 5e80268da7..63448cd7d4 100644
--- a/components/esp_system/ld/ld.cmake
+++ b/components/esp_system/ld/ld.cmake
@@ -9,25 +9,31 @@ idf_build_get_property(sdkconfig_header SDKCONFIG_HEADER)
 
 set(ld_input "${CMAKE_CURRENT_LIST_DIR}/${target}/memory.ld.in")
 set(ld_output "${CMAKE_CURRENT_BINARY_DIR}/ld/memory.ld")
+set(sections_input "${CMAKE_CURRENT_LIST_DIR}/${target}/sections.ld.in")
+set(sections_output "${CMAKE_CURRENT_BINARY_DIR}/ld/sections.preprocess.ld")
+
 target_linker_script(${COMPONENT_LIB} INTERFACE "${ld_output}")
 
 file(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/ld")
 
 # Process the template file through the linker script generation mechanism, and use the output for linking the
 # final binary
-target_linker_script(${COMPONENT_LIB} INTERFACE "${CMAKE_CURRENT_LIST_DIR}/${target}/sections.ld.in"
-                    PROCESS "${CMAKE_CURRENT_BINARY_DIR}/ld/sections.ld")
+target_linker_script(${COMPONENT_LIB} INTERFACE ${sections_output}
+                        PROCESS "${CMAKE_CURRENT_BINARY_DIR}/ld/sections.ld")
 
 idf_build_get_property(config_dir CONFIG_DIR)
+
 # Preprocess memory.ld.in linker script to include configuration, becomes memory.ld
 add_custom_command(
-    OUTPUT ${ld_output}
+    OUTPUT ${ld_output} ${sections_output}
     COMMAND "${CMAKE_C_COMPILER}" -C -P -x c -E -o ${ld_output} -I ${config_dir}
             -I "${CMAKE_CURRENT_LIST_DIR}" ${ld_input}
-    MAIN_DEPENDENCY ${ld_input}
+    COMMAND "${CMAKE_C_COMPILER}" -C -P -x c -E -o ${sections_output} -I ${config_dir}
+            -I "${CMAKE_CURRENT_LIST_DIR}" ${sections_input}
+    MAIN_DEPENDENCY ${ld_input} ${sections_input}
     DEPENDS ${sdkconfig_header}
     COMMENT "Generating memory.ld linker script..."
     VERBATIM)
 
-add_custom_target(memory_ld DEPENDS ${ld_output})
+add_custom_target(memory_ld DEPENDS ${ld_output} ${sections_output})
 add_dependencies(${COMPONENT_LIB} memory_ld)
diff --git a/components/freertos/port/xtensa/portasm.S b/components/freertos/port/xtensa/portasm.S
index 0fbbdb8d51..eb8fb199dd 100644
--- a/components/freertos/port/xtensa/portasm.S
+++ b/components/freertos/port/xtensa/portasm.S
@@ -25,10 +25,23 @@
 
 #include "xtensa_rtos.h"
 #include "sdkconfig.h"
+#include "soc/sensitive_reg.h"
+#include "soc/world_controller_reg.h"
 
 #define TOPOFSTACK_OFFS                 0x00    /* StackType_t *pxTopOfStack */
 #define CP_TOPOFSTACK_OFFS              0x04    /* xMPU_SETTINGS.coproc_area */
 
+/*
+ * uxTCBNumber and uxTaskNumber members are added in TCB structure when
+ * FreeRTOS Trace facility is enabled. WORLD offset is changed by 8 bytes
+ * because both members are 4 bytes in size.
+ */
+#ifdef CONFIG_FREERTOS_USE_TRACE_FACILITY
+#define WORLD_OFFSET    (0x4c + CONFIG_FREERTOS_MAX_TASK_NAME_LEN + 3 + 8)&~3
+#else
+#define WORLD_OFFSET    (0x4c + CONFIG_FREERTOS_MAX_TASK_NAME_LEN + 3 + 4)&~3
+#endif
+
 .extern pxCurrentTCB
 
 /*
@@ -111,6 +124,26 @@ _frxt_int_enter:
     /* Save the rest of the interrupted context (preserves A12-13). */
     call0   _xt_context_save
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    /* Save WORLD in Thread Local Storage */
+    movi    a2, WORLD_CONTROLLER_WCL_CORE_0_STATUSTABLE1_REG
+    l32i    a3, a2, 0
+    // Zero out the table entry
+    movi    a4, 0
+    s32i    a4, a2, 0
+    // Extract the value at WORLD bit
+    movi    a2, 1
+    and     a2, a3, a2
+
+    getcoreid a4
+
+    movi    a3,  pxCurrentTCB
+    addx4	a3,  a4, a3
+    l32i    a3,  a3, 0
+    s32i    a2,  a3, WORLD_OFFSET
+    memw
+#endif
+
     /*
     Save interrupted task's SP in TCB only if not nesting.
     Manage nesting directly rather than call the generic IntEnter()
@@ -244,6 +277,34 @@ _frxt_int_exit:
     In either case there's no need to load the SP.
     */
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    /* Restore WORLD from the TLS */
+    getcoreid a4
+    movi    a2,  pxCurrentTCB
+    addx4	a2,  a4, a2
+    l32i    a2,  a2, 0
+    l32i    a3,  a2, WORLD_OFFSET
+    beqz    a3,  .skip_restore_world
+
+    movi    a3, 2
+    /*TODO: Decide register based on core in case of dual core setup */
+    movi    a4, WORLD_CONTROLLER_WCL_CORE_0_WORLD_PREPARE_REG
+    s32i    a3, a4, 0
+
+    /* Set TRIGGER_ADDR to the return address; held by EPC */
+    l32i    a3, a1, XT_STK_PC
+    movi    a4, WORLD_CONTROLLER_WCL_CORE_0_WORLD_TRIGGER_ADDR_REG
+    s32i    a3, a4, 0
+
+    movi    a3, 1
+    /*TODO: Decide register based on core in case of dual core setup */
+    movi    a4, WORLD_CONTROLLER_WCL_CORE_0_WORLD_UPDATE_REG
+    s32i    a3, a4, 0
+
+.skip_restore_world:
+    memw
+#endif
+
     /* Restore full context from interrupt stack frame */
     call0   _xt_context_restore
 
@@ -442,6 +503,30 @@ _frxt_dispatch:
     l32i    sp,  a3, TOPOFSTACK_OFFS     /* SP = next_TCB->pxTopOfStack;  */
     s32i    a3,  a2, 0
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    /* Restore WORLD from the TLS */
+    l32i    a4,  a3, WORLD_OFFSET
+    beqz    a4,  1f
+
+    movi    a3, 2
+    /*TODO: Decide register based on core in case of dual core setup */
+    movi    a4, WORLD_CONTROLLER_WCL_CORE_0_WORLD_PREPARE_REG
+    s32i    a3, a4, 0
+
+    /* Set TRIGGER_ADDR to the return address; held by EPC */
+    l32i    a3, a1, XT_STK_PC
+    movi    a4, WORLD_CONTROLLER_WCL_CORE_0_WORLD_TRIGGER_ADDR_REG
+    s32i    a3, a4, 0
+
+    movi    a3, 1
+    /*TODO: Decide register based on core in case of dual core setup */
+    movi    a4, WORLD_CONTROLLER_WCL_CORE_0_WORLD_UPDATE_REG
+    s32i    a3, a4, 0
+
+1:
+    memw
+#endif
+
     /* Determine the type of stack frame. */
     l32i    a2,  sp, XT_STK_EXIT        /* exit dispatcher or solicited flag */
     bnez    a2,  .L_frxt_dispatch_stk
@@ -571,10 +656,29 @@ vPortYield:
     call0   _xt_coproc_savecs
     #endif
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    /* vPortYield does not raise an interrupt before switching context,
+     * so we read the debug register to know the current WORLD
+     */
+    movi    a2, WORLD_CONTROLLER_WCL_CORE_0_WORLD_IRAM0_REG
+    l32i    a3, a2, 0
+    // Extract the WORLD1 bit
+    movi    a4, 2
+    and     a4, a3, a4
+
+    movi    a2,  pxCurrentTCB
+    getcoreid a3
+    addx4	a2,  a3, a2
+    l32i    a2,  a2, 0                  /* a2 = pxCurrentTCB                */
+    /* Store the WORLD */
+    s32i    a4,  a2, WORLD_OFFSET
+#else
     movi    a2,  pxCurrentTCB
 	getcoreid a3
 	addx4	a2,  a3, a2
     l32i    a2,  a2, 0                  /* a2 = pxCurrentTCB                */
+#endif
+
     movi    a3,  0
     s32i    a3,  sp, XT_SOL_EXIT        /* 0 to flag as solicited frame     */
     s32i    sp,  a2, TOPOFSTACK_OFFS    /* pxCurrentTCB->pxTopOfStack = SP  */
diff --git a/components/freertos/port/xtensa/xtensa_vector_defaults.S b/components/freertos/port/xtensa/xtensa_vector_defaults.S
index 791116cfbc..4a0e466da4 100644
--- a/components/freertos/port/xtensa/xtensa_vector_defaults.S
+++ b/components/freertos/port/xtensa/xtensa_vector_defaults.S
@@ -236,3 +236,69 @@ _xt_nmi:
     rfi     XCHAL_NMILEVEL
 
 #endif  /* NMI */
+
+    .global  _xt_syscall_exc
+    .weak _xt_syscall_exc
+    .set _xt_syscall_exc, _xt_default_syscall_exc
+    .section .iram1,"ax"
+    .type       _xt_default_syscall_exc,@function
+    .align      4
+
+_xt_default_syscall_exc:
+    #ifdef __XTENSA_CALL0_ABI__
+    /*
+    Save minimal regs for scratch. Syscall 0 does nothing in Call0 ABI.
+    Use a minimal stack frame (16B) to save A2 & A3 for scratch.
+    PS.EXCM could be cleared here, but unlikely to improve worst-case latency.
+    rsr     a0, PS
+    addi    a0, a0, -PS_EXCM_MASK
+    wsr     a0, PS
+    */
+    addi    sp, sp, -16
+    s32i    a2, sp, 8
+    s32i    a3, sp, 12
+    #else   /* Windowed ABI */
+    /*
+    Save necessary context and spill the register windows.
+    PS.EXCM is still set and must remain set until after the spill.
+    Reuse context save function though it saves more than necessary.
+    For this reason, a full interrupt stack frame is allocated.
+    */
+    addi    sp, sp, -XT_STK_FRMSZ           /* allocate interrupt stack frame */
+    s32i    a12, sp, XT_STK_A12             /* _xt_context_save requires A12- */
+    s32i    a13, sp, XT_STK_A13             /* A13 to have already been saved */
+    call0   _xt_context_save
+    #endif
+
+    /*
+    Grab the interruptee's PC and skip over the 'syscall' instruction.
+    If it's at the end of a zero-overhead loop and it's not on the last
+    iteration, decrement loop counter and skip to beginning of loop.
+    */
+    rsr     a2, EPC_1                       /* a2 = PC of 'syscall' */
+    addi    a3, a2, 3                       /* ++PC                 */
+    #if XCHAL_HAVE_LOOPS
+    rsr     a0, LEND                        /* if (PC == LEND       */
+    bne     a3, a0, 1f
+    rsr     a0, LCOUNT                      /*     && LCOUNT != 0)  */
+    beqz    a0, 1f                          /* {                    */
+    addi    a0, a0, -1                      /*   --LCOUNT           */
+    rsr     a3, LBEG                        /*   PC = LBEG          */
+    wsr     a0, LCOUNT                      /* }                    */
+    #endif
+
+1:
+    wsr     a3, EPC_1                       /* update PC            */
+
+    /* Restore interruptee's context and return from exception. */
+    #ifdef __XTENSA_CALL0_ABI__
+    l32i    a2, sp, 8
+    l32i    a3, sp, 12
+    addi    sp, sp, 16
+    #else
+    call0   _xt_context_restore
+    addi    sp, sp, XT_STK_FRMSZ
+    #endif
+
+    rsr     a0, EXCSAVE_1
+    rfe
diff --git a/components/freertos/port/xtensa/xtensa_vectors.S b/components/freertos/port/xtensa/xtensa_vectors.S
index 1560ff27d6..683247341b 100644
--- a/components/freertos/port/xtensa/xtensa_vectors.S
+++ b/components/freertos/port/xtensa/xtensa_vectors.S
@@ -94,6 +94,8 @@ SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 #include "esp_private/panic_reason.h"
 #include "sdkconfig.h"
 #include "soc/soc.h"
+#include "soc/sensitive_reg.h"
+#include "soc/extmem_reg.h"
 
 /*
   Define for workaround: pin no-cpu-affinity tasks to a cpu when fpu is used.
@@ -571,6 +573,14 @@ _call_alignment_handler:
     j       .LS_exit
 #endif
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    .align      4
+_xt_perm_violation:
+    movi    a0, EXCCAUSE_LEVEL1INTERRUPT
+    wsr     a0, EXCCAUSE
+    j       _xt_lowint1
+#endif
+
 /*
 --------------------------------------------------------------------------------
   User exception handler.
@@ -581,7 +591,27 @@ _call_alignment_handler:
     .align      4
 
 _xt_user_exc:
-
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    wsr     a2, DEPC
+    movi    a0, 0x50000000
+    movi    a2, 0
+    s32i    a2, a0, 0
+    addi    a2, a2, 1
+    s32i    a2, a0, 0
+    addi    a2, a2, 1
+    s32i    a2, a0, 0
+    addi    a2, a2, 1
+    s32i    a2, a0, 0
+    addi    a2, a2, 1
+    s32i    a2, a0, 0
+    addi    a2, a2, 1
+    s32i    a2, a0, 0
+    addi    a2, a2, 1
+    s32i    a2, a0, 0
+    l32i    a0, a0, 0
+    memw
+    rsr     a2, DEPC
+#endif
     /* If level 1 interrupt then jump to the dispatcher */
     rsr     a0, EXCCAUSE
     beqi    a0, EXCCAUSE_LEVEL1INTERRUPT, _xt_lowint1
@@ -608,6 +638,32 @@ _xt_user_exc:
 .LS_exit:
 #endif
 
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    /* Check for IRAM violation */
+    movi    a0, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG
+    l32i    a0, a0, 0
+    extui   a0, a0, 0, 1
+    beqi    a0, 1, _xt_perm_violation
+
+    /* Check for DRAM violation */
+    movi    a0, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_2_REG
+    l32i    a0, a0, 0
+    extui   a0, a0, 0, 1
+    beqi    a0, 1, _xt_perm_violation
+
+    /* Check for IBUS Cache violation */
+    movi    a0, EXTMEM_CORE0_ACS_CACHE_INT_ST_REG
+    l32i    a0, a0, 0
+    extui   a0, a0, 0, 3
+    bgei    a0, 1, _xt_perm_violation
+
+    /* Check for DBUS Cache violation */
+    movi    a0, EXTMEM_CORE0_ACS_CACHE_INT_ST_REG
+    l32i    a0, a0, 0
+    extui   a0, a0, 2, 3
+    bgei    a0, 1, _xt_perm_violation
+#endif
+
     /* Handle all other exceptions. All can have user-defined handlers. */
     /* NOTE: we'll stay on the user stack for exception handling.       */
 
@@ -738,77 +794,6 @@ _xt_user_exit:
     rfe                                     /* PS.EXCM is cleared */
 
 
-/*
-
---------------------------------------------------------------------------------
-Syscall Exception Handler (jumped to from User Exception Handler).
-Syscall 0 is required to spill the register windows (no-op in Call 0 ABI).
-Only syscall 0 is handled here. Other syscalls return -1 to caller in a2.
---------------------------------------------------------------------------------
-*/
-
-    .section .iram1,"ax"
-    .type       _xt_syscall_exc,@function
-    .align      4
-_xt_syscall_exc:
-
-    #ifdef __XTENSA_CALL0_ABI__
-    /*
-    Save minimal regs for scratch. Syscall 0 does nothing in Call0 ABI.
-    Use a minimal stack frame (16B) to save A2 & A3 for scratch.
-    PS.EXCM could be cleared here, but unlikely to improve worst-case latency.
-    rsr     a0, PS
-    addi    a0, a0, -PS_EXCM_MASK
-    wsr     a0, PS
-    */
-    addi    sp, sp, -16
-    s32i    a2, sp, 8
-    s32i    a3, sp, 12
-    #else   /* Windowed ABI */
-    /*
-    Save necessary context and spill the register windows.
-    PS.EXCM is still set and must remain set until after the spill.
-    Reuse context save function though it saves more than necessary.
-    For this reason, a full interrupt stack frame is allocated.
-    */
-    addi    sp, sp, -XT_STK_FRMSZ           /* allocate interrupt stack frame */
-    s32i    a12, sp, XT_STK_A12             /* _xt_context_save requires A12- */
-    s32i    a13, sp, XT_STK_A13             /* A13 to have already been saved */
-    call0   _xt_context_save
-    #endif
-
-    /*
-    Grab the interruptee's PC and skip over the 'syscall' instruction.
-    If it's at the end of a zero-overhead loop and it's not on the last
-    iteration, decrement loop counter and skip to beginning of loop.
-    */
-    rsr     a2, EPC_1                       /* a2 = PC of 'syscall' */
-    addi    a3, a2, 3                       /* ++PC                 */
-    #if XCHAL_HAVE_LOOPS
-    rsr     a0, LEND                        /* if (PC == LEND       */
-    bne     a3, a0, 1f
-    rsr     a0, LCOUNT                      /*     && LCOUNT != 0)  */
-    beqz    a0, 1f                          /* {                    */
-    addi    a0, a0, -1                      /*   --LCOUNT           */
-    rsr     a3, LBEG                        /*   PC = LBEG          */
-    wsr     a0, LCOUNT                      /* }                    */
-    #endif
-1:  wsr     a3, EPC_1                       /* update PC            */
-
-    /* Restore interruptee's context and return from exception. */
-    #ifdef __XTENSA_CALL0_ABI__
-    l32i    a2, sp, 8
-    l32i    a3, sp, 12
-    addi    sp, sp, 16
-    #else
-    call0   _xt_context_restore
-    addi    sp, sp, XT_STK_FRMSZ
-    #endif
-    movi    a0, -1
-    movnez  a2, a0, a2                      /* return -1 if not syscall 0 */
-    rsr     a0, EXCSAVE_1
-    rfe
-
 /*
 --------------------------------------------------------------------------------
 Co-Processor Exception Handler (jumped to from User Exception Handler).
diff --git a/components/hal/esp32s3/include/hal/memprot_ll.h b/components/hal/esp32s3/include/hal/memprot_ll.h
index 41410cc80f..b2643df0b4 100644
--- a/components/hal/esp32s3/include/hal/memprot_ll.h
+++ b/components/hal/esp32s3/include/hal/memprot_ll.h
@@ -1,655 +1,1630 @@
-// Copyright 2020 Espressif Systems (Shanghai) PTE LTD
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
+/*
+ * SPDX-FileCopyrightText: 2020-2022 Espressif Systems (Shanghai) CO LTD
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ */
 
 #pragma once
 
+#include "soc/ext_mem_defs.h"
+#include "soc/memprot_defs.h"
+#include "hal/memprot_types.h"
+
+/* Uncomment to enable MPS debug assertions on false register writes.
+ * It irregularly happens the PMS registers cannot be written which causes unpredictable malfunction of the Memprot feature
+ * Once the issue is found & resolved, the assertions can be removed
+ */
+//#define PMS_DEBUG_ASSERTIONS
+
+#ifdef PMS_DEBUG_ASSERTIONS
 #include "hal/assert.h"
+#endif
 
 #ifdef __cplusplus
 extern "C" {
 #endif
 
-// not implemented for esp32s3 yet
-#if 0
-/**
- * === IRAM0 ====
- */
+//highest address of each Level slot in the SRAM's 3rd memory region (I/D access, 416kB)
+//quick resolver of split-address category bits
+static const intptr_t sram_rg3_level_hlimits[] = {
+        0x4037FFFF, //level 2 (32KB)
+        0x4038FFFF, //level 3 (64KB)
+        0x4039FFFF, //level 4 (64KB)
+        0x403AFFFF, //level 5 (64KB)
+        0x403BFFFF, //level 6 (64KB)
+        0x403CFFFF, //level 7 (64KB)
+        0x403DFFFF  //level 8 (64KB)
+};
+
+/* ******************************************************************************************************
+ * *** COMMON ***
+ * ******************************************************************************************************/
+static inline void memprot_ll_set_iram0_dram0_split_line_lock(void)
+{
+    REG_WRITE(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_0_REG) == 1) && "Value not stored to required register");
+#endif
+}
 
-#define IRAM0_TOTAL_UNI_BLOCKS          4
-#define IRAM0_UNI_BLOCK_0               0
-#define IRAM0_UNI_BLOCK_1               1
-#define IRAM0_UNI_BLOCK_2               2
-#define IRAM0_UNI_BLOCK_3               3
+static inline bool memprot_ll_get_iram0_dram0_split_line_lock(void)
+{
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_0_REG) == 1;
+}
 
-#define IRAM0_SPL_BLOCK_BASE            0x40000000
+static inline void *memprot_ll_get_split_addr_from_reg(const uint32_t regval, const uint32_t base)
+{
+    constrain_reg_fields_t reg_val;
+    reg_val.val = regval;
+
+    uint32_t off = reg_val.splitaddr << I_D_SPLIT_LINE_SHIFT;
+    uint32_t level_off = 0;
+
+    do {
+        if (reg_val.cat0 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        level_off += I_D_SRAM_SEGMENT_SIZE/2;
+        if (reg_val.cat1 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        level_off += I_D_SRAM_SEGMENT_SIZE;
+        if (reg_val.cat2 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        level_off += I_D_SRAM_SEGMENT_SIZE;
+        if (reg_val.cat3 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        level_off += I_D_SRAM_SEGMENT_SIZE;
+        if (reg_val.cat4 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        level_off += I_D_SRAM_SEGMENT_SIZE;
+        if (reg_val.cat5 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        level_off += I_D_SRAM_SEGMENT_SIZE;
+        if (reg_val.cat6 == MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA) break;
+        return NULL; //wrong configuration
+    } while(0);
+
+    return (void *)(base + level_off + off);
+}
 
-//unified management (SRAM blocks 0-3)
-#define IRAM0_UNI_BLOCK_0_LOW           0x40020000
-#define IRAM0_UNI_BLOCK_0_HIGH          0x40021FFF
-#define IRAM0_UNI_BLOCK_1_LOW           0x40022000
-#define IRAM0_UNI_BLOCK_1_HIGH          0x40023FFF
-#define IRAM0_UNI_BLOCK_2_LOW           0x40024000
-#define IRAM0_UNI_BLOCK_2_HIGH          0x40025FFF
-#define IRAM0_UNI_BLOCK_3_LOW           0x40026000
-#define IRAM0_UNI_BLOCK_3_HIGH          0x40027FFF
+/* ******************************************************************************************************
+ * *** IRAM0 ***
+ * ******************************************************************************************************/
+static inline memprot_ll_err_t memprot_ll_iram0_get_intr_source_num(const int core, uint32_t* src_num)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *src_num = ETS_CORE0_IRAM0_PMS_INTR_SOURCE;
+            break;
+        case APP_CPU_NUM:
+            *src_num = ETS_CORE1_IRAM0_PMS_INTR_SOURCE;
+            break;
+        default:
+            return MEMP_LL_FAIL;
+    }
 
-//split management (SRAM blocks 4-21)
-#define IRAM0_SPL_BLOCK_LOW             0x40028000 //block 4 low
-#define IRAM0_SPL_BLOCK_HIGH            0x4006FFFF //block 21 high
-#define IRAM0_SPLTADDR_MIN              0x40030000 //block 6 low - minimum splitting address
+    return MEMP_LL_OK;
+}
 
-//IRAM0 interrupt status bitmasks
-#define IRAM0_INTR_ST_FAULTADDR_M       0x003FFFFC  //(bits 21:6 in the reg, as well as in real address)
-#define IRAM0_INTR_ST_FAULTADDR_HI      0x40000000  //(high nonsignificant bits 31:22 of the faulting address - constant)
-#define IRAM0_INTR_ST_OP_TYPE_BIT       BIT(1)      //instruction: 0, data: 1
-#define IRAM0_INTR_ST_OP_RW_BIT         BIT(0)      //read: 0, write: 1
+///////////////////////////////////
+// IRAM0 - SPLIT LINES
+static inline uint32_t memprot_ll_get_iram0_split_line_main_I_D_regval(void)
+{
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_1_REG);
+}
 
+static inline uint32_t memprot_ll_get_iram0_split_line_main_I_0_regval(void)
+{
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_2_REG);
+}
 
-static inline uint32_t esp_memprot_iram0_get_intr_source_num(void)
+static inline uint32_t memprot_ll_get_iram0_split_line_main_I_1_regval(void)
 {
-    return ETS_PMS_PRO_IRAM0_ILG_INTR_SOURCE;
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_3_REG);
 }
 
-static inline void esp_memprot_iram0_intr_ena(bool enable)
+static inline void memprot_ll_prepare_iram0_split_line_regval(const uint32_t addr, uint32_t* regval)
 {
-    if ( enable ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_EN );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_EN );
+    //set category bits for given split line
+    uint32_t cat[7] = {[0 ... 6]=MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_ABOVE_SA};
+    for (size_t x=0; x<7; x++) {
+        if (addr <= sram_rg3_level_hlimits[x]) {
+            cat[x] = MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA;
+            break;
+        } else {
+            cat[x] = MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_BELOW_SA;
+        }
     }
+
+    //resolve split address' significant bits
+    uint32_t conf_add = ((addr >> I_D_SPLIT_LINE_SHIFT) & SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SRAM_SPLITADDR_V);
+
+    //write values to required configuration-register
+    constrain_reg_fields_t cfg_reg_val = {
+            .cat0 = cat[0],
+            .cat1 = cat[1],
+            .cat2 = cat[2],
+            .cat3 = cat[3],
+            .cat4 = cat[4],
+            .cat5 = cat[5],
+            .cat6 = cat[6],
+            .splitaddr = conf_add,
+            .reserved = 0
+    };
+
+    *regval = cfg_reg_val.val;
 }
 
-static inline uint32_t esp_memprot_iram0_get_ena_reg(void)
+// all the split lines registers have the same layout
+static inline memprot_ll_err_t memprot_ll_set_iram0_split_line(const void *line_addr, const uint32_t sensitive_reg)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_IRAM0_4_REG);
+    uint32_t addr = (uint32_t)line_addr;
+
+    //sanity check
+    MEMP_LL_CHECK_IRAM_ADDR_IN_RANGE(addr)
+    MEMP_LL_CHECK_SPLIT_ADDR_ALIGNED(addr)
+
+    uint32_t regval;
+    memprot_ll_prepare_iram0_split_line_regval(addr, &regval);
+
+    REG_WRITE(sensitive_reg, regval);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((REG_READ(sensitive_reg) == regval) && "Value not stored to required register");
+#endif
+
+    return MEMP_LL_OK;
 }
 
-static inline uint32_t esp_memprot_iram0_get_fault_reg(void)
+// set the main I/D splitting address - can be defined within either IRAM0 or DRAM0 range (IRAM0 preferred as the Memprot API stereotype)
+static inline memprot_ll_err_t memprot_ll_set_iram0_split_line_main_I_D(const void *line_addr)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_IRAM0_5_REG);
+    return memprot_ll_set_iram0_split_line(line_addr, SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_1_REG);
 }
 
-static inline void esp_memprot_iram0_get_fault_status(uint32_t **faulting_address, uint32_t *op_type, uint32_t *op_subtype)
+// set auxiliary split lines (IRAM0 range address required)
+static inline memprot_ll_err_t memprot_ll_set_iram0_split_line_I_0(const void *line_addr)
 {
-    uint32_t status_bits = esp_memprot_iram0_get_fault_reg();
+    return memprot_ll_set_iram0_split_line(line_addr, SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_2_REG);
+}
 
-    uint32_t fault_addr = (status_bits & IRAM0_INTR_ST_FAULTADDR_M);
-    *faulting_address = (uint32_t *)(fault_addr | IRAM0_INTR_ST_FAULTADDR_HI);
+static inline memprot_ll_err_t memprot_ll_set_iram0_split_line_I_1(const void *line_addr)
+{
+    return memprot_ll_set_iram0_split_line(line_addr, SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_3_REG);
+}
 
-    *op_type = (uint32_t)status_bits & IRAM0_INTR_ST_OP_RW_BIT;
-    *op_subtype = (uint32_t)status_bits & IRAM0_INTR_ST_OP_TYPE_BIT;
+// get configured category bits
+static inline uint32_t memprot_ll_get_iram0_split_line_main_I_D_cat(void)
+{
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_1_REG) & 0x3FFF;
 }
 
-static inline bool esp_memprot_iram0_is_assoc_intr(void)
+static inline uint32_t memprot_ll_get_iram0_split_line_I_0_cat(void)
 {
-    return DPORT_GET_PERI_REG_MASK(DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_INTR) > 0;
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_2_REG) & 0x3FFF;
 }
 
-static inline void esp_memprot_iram0_clear_intr(void)
+static inline uint32_t memprot_ll_get_iram0_split_line_I_1_cat(void)
 {
-    DPORT_SET_PERI_REG_MASK(DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_CLR);
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_3_REG) & 0x3FFF;
 }
 
-static inline uint32_t esp_memprot_iram0_get_intr_ena_bit(void)
+// get configured splitting address (IRAM0-based)
+static inline void *memprot_ll_get_iram0_split_line_main_I_D(void)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_EN);
+    return memprot_ll_get_split_addr_from_reg(REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_1_REG), SOC_DIRAM_IRAM_LOW);
 }
 
-static inline uint32_t esp_memprot_iram0_get_intr_on_bit(void)
+static inline void *memprot_ll_get_iram0_split_line_I_0(void)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_INTR);
+    return memprot_ll_get_split_addr_from_reg(REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_2_REG), SOC_DIRAM_IRAM_LOW);
 }
 
-static inline uint32_t esp_memprot_iram0_get_intr_clr_bit(void)
+static inline void *memprot_ll_get_iram0_split_line_I_1(void)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_IRAM0_4_REG, DPORT_PMS_PRO_IRAM0_ILG_CLR);
+    return memprot_ll_get_split_addr_from_reg(REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_3_REG), SOC_DIRAM_IRAM_LOW);
 }
 
-//resets automatically on CPU restart
-static inline void esp_memprot_iram0_set_lock(void)
+///////////////////////////////////
+// IRAM0 - PMS CONFIGURATION
+
+// lock
+static inline void memprot_ll_iram0_set_pms_lock(void)
 {
-    DPORT_WRITE_PERI_REG( DPORT_PMS_PRO_IRAM0_0_REG, DPORT_PMS_PRO_IRAM0_LOCK);
+    REG_WRITE(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((REG_READ(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_0_REG) == 1) && "Value not stored to required register");
+#endif
 }
 
-static inline uint32_t esp_memprot_iram0_get_lock_reg(void)
+static inline bool memprot_ll_iram0_get_pms_lock(void)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_IRAM0_0_REG);
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_0_REG) == 1;
 }
 
-static inline uint32_t esp_memprot_iram0_get_lock_bit(void)
+// permission settings
+static inline uint32_t memprot_ll_iram0_set_permissions(const bool r, const bool w, const bool x)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_IRAM0_0_REG, DPORT_PMS_PRO_IRAM0_LOCK);
+    uint32_t permissions = 0;
+    if (r) {
+        permissions |= SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_R;
+    }
+    if (w) {
+        permissions |= SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_W;
+    }
+    if (x) {
+        permissions |= SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_F;
+    }
+
+    return permissions;
 }
 
-//block 0-3
-static inline void esp_memprot_iram0_set_uni_block_perm(uint32_t block, bool write_perm, bool read_perm, bool exec_perm)
+static inline void memprot_ll_iram0_set_pms_area_0(const bool r, const bool w, const bool x)
 {
-    HAL_ASSERT(block < IRAM0_TOTAL_UNI_BLOCKS);
+    REG_SET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_0, memprot_ll_iram0_set_permissions(r, w, x));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_0);
+    HAL_ASSERT((expected == memprot_ll_iram0_set_permissions(r, w, x)) && "Value not stored to required register");
+#endif
+}
 
-    uint32_t write_bit, read_bit, exec_bit;
-    switch ( block ) {
-    case IRAM0_UNI_BLOCK_0:
-        write_bit = DPORT_PMS_PRO_IRAM0_SRAM_0_W;
-        read_bit = DPORT_PMS_PRO_IRAM0_SRAM_0_R;
-        exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_0_F;
-        break;
-    case IRAM0_UNI_BLOCK_1:
-        write_bit = DPORT_PMS_PRO_IRAM0_SRAM_1_W;
-        read_bit = DPORT_PMS_PRO_IRAM0_SRAM_1_R;
-        exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_1_F;
-        break;
-    case IRAM0_UNI_BLOCK_2:
-        write_bit = DPORT_PMS_PRO_IRAM0_SRAM_2_W;
-        read_bit = DPORT_PMS_PRO_IRAM0_SRAM_2_R;
-        exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_2_F;
-        break;
-    case IRAM0_UNI_BLOCK_3:
-        write_bit = DPORT_PMS_PRO_IRAM0_SRAM_3_W;
-        read_bit = DPORT_PMS_PRO_IRAM0_SRAM_3_R;
-        exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_3_F;
-        break;
-    default:
-        abort();
+static inline void memprot_ll_iram0_set_pms_area_1(const bool r, const bool w, const bool x)
+{
+    REG_SET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_1, memprot_ll_iram0_set_permissions(r, w, x));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_1);
+    HAL_ASSERT((expected == memprot_ll_iram0_set_permissions(r, w, x)) && "Value not stored to required register");
+#endif
+}
+
+static inline void memprot_ll_iram0_set_pms_area_2(const bool r, const bool w, const bool x)
+{
+    REG_SET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_2, memprot_ll_iram0_set_permissions(r, w, x));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_2);
+    HAL_ASSERT((expected == memprot_ll_iram0_set_permissions(r, w, x)) && "Value not stored to required register");
+#endif
+}
+
+static inline void memprot_ll_iram0_set_pms_area_3(const bool r, const bool w, const bool x)
+{
+    REG_SET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_3, memprot_ll_iram0_set_permissions(r, w, x));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_3);
+    HAL_ASSERT((expected == memprot_ll_iram0_set_permissions(r, w, x)) && "Value not stored to required register");
+#endif
+}
+
+static inline void memprot_ll_iram0_get_permissions(const uint32_t perms, bool *r, bool *w, bool *x)
+{
+    *r = perms & SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_R;
+    *w = perms & SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_W;
+    *x = perms & SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_F;
+}
+
+static inline void memprot_ll_iram0_get_pms_area_0(bool *r, bool *w, bool *x)
+{
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_0);
+    memprot_ll_iram0_get_permissions(permissions, r, w, x);
+}
+
+static inline void memprot_ll_iram0_get_pms_area_1(bool *r, bool *w, bool *x)
+{
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_1);
+    memprot_ll_iram0_get_permissions(permissions, r, w, x);
+}
+
+static inline void memprot_ll_iram0_get_pms_area_2(bool *r, bool *w, bool *x)
+{
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_2);
+    memprot_ll_iram0_get_permissions(permissions, r, w, x);
+}
+
+static inline void memprot_ll_iram0_get_pms_area_3(bool *r, bool *w, bool *x)
+{
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_2_REG, SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_3);
+    memprot_ll_iram0_get_permissions(permissions, r, w, x);
+}
+
+
+///////////////////////////////////
+// IRAM0 - MONITOR
+
+// lock
+static inline memprot_ll_err_t memprot_ll_iram0_set_monitor_lock(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    if ( write_perm ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_1_REG, write_bit );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_1_REG, write_bit );
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_lock(const int core, bool* locked)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_0_REG) == 1;
+            break;
+        case APP_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_0_REG) == 1;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    if ( read_perm ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_1_REG, read_bit );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_1_REG, read_bit );
+    return MEMP_LL_OK;
+}
+
+// interrupt enable/clear
+static inline memprot_ll_err_t memprot_ll_iram0_set_monitor_en(const int core, const bool enable)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            if (enable) {
+                REG_SET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_EN) > 0) && "Value not stored to required register");
+#endif
+            } else {
+                REG_CLR_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_EN) == 0) && "Value not stored to required register");
+#endif
+            }
+            break;
+        case APP_CPU_NUM:
+            if (enable) {
+                REG_SET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_EN) > 0) && "Value not stored to required register");
+#endif
+            } else {
+                REG_CLR_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_EN) == 0) && "Value not stored to required register");
+#endif
+            }
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    if ( exec_perm ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_1_REG, exec_bit );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_IRAM0_1_REG, exec_bit );
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_en(const int core, bool* enabled)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *enabled = REG_GET_FIELD(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_EN) == 1;
+            break;
+        case APP_CPU_NUM:
+            *enabled = REG_GET_FIELD(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_EN) == 1;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
+
+    return MEMP_LL_OK;
 }
 
-static inline uint32_t esp_memprot_iram0_get_uni_block_read_bit(uint32_t block)
+static inline memprot_ll_err_t memprot_ll_iram0_set_monitor_intrclr(const int core)
 {
-    HAL_ASSERT(block < IRAM0_TOTAL_UNI_BLOCKS);
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_SET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_CLR) > 0) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_SET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_CLR) > 0) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-    switch ( block ) {
-    case IRAM0_UNI_BLOCK_0:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_0_R );
-    case IRAM0_UNI_BLOCK_1:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_1_R );
-    case IRAM0_UNI_BLOCK_2:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_2_R );
-    case IRAM0_UNI_BLOCK_3:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_3_R );
-    default:
-        abort();
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_reset_monitor_intrclr(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_CLR_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_CLR) == 0) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_CLR_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_CLR) == 0) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
+
+    return MEMP_LL_OK;
 }
 
-static inline uint32_t esp_memprot_iram0_get_uni_block_write_bit(uint32_t block)
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_intrclr(const int core, bool* cleared)
 {
-    HAL_ASSERT(block < IRAM0_TOTAL_UNI_BLOCKS);
+    switch (core) {
+        case PRO_CPU_NUM:
+            *cleared = REG_GET_BIT(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_CLR) > 0;
+            break;
+        case APP_CPU_NUM:
+            *cleared = REG_GET_BIT(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_CLR) > 0;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-    switch ( block ) {
-    case IRAM0_UNI_BLOCK_0:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_0_W );
-    case IRAM0_UNI_BLOCK_1:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_1_W );
-    case IRAM0_UNI_BLOCK_2:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_2_W );
-    case IRAM0_UNI_BLOCK_3:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_3_W );
-    default:
-        abort();
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_enable_register(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_1_REG);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_1_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
+
+    return MEMP_LL_OK;
 }
 
-static inline uint32_t esp_memprot_iram0_get_uni_block_exec_bit(uint32_t block)
+// permission violation status
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_status_intr(const int core, uint32_t* regval)
 {
-    HAL_ASSERT(block < IRAM0_TOTAL_UNI_BLOCKS);
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_INTR);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_INTR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-    switch ( block ) {
-    case IRAM0_UNI_BLOCK_0:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_0_F );
-    case IRAM0_UNI_BLOCK_1:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_1_F );
-    case IRAM0_UNI_BLOCK_2:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_2_F );
-    case IRAM0_UNI_BLOCK_3:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_1_REG, DPORT_PMS_PRO_IRAM0_SRAM_3_F );
-    default:
-        abort();
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_status_fault_wr(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_STATUS_WR);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_STATUS_WR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_status_fault_loadstore(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_STATUS_LOADSTORE);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_STATUS_LOADSTORE);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_status_fault_world(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_STATUS_WORLD);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_STATUS_WORLD);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_status_fault_addr(const int core, void** addr)
+{
+    uint32_t reg_off;
+
+    switch (core) {
+        case PRO_CPU_NUM:
+            reg_off = REG_GET_FIELD(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_VIOLATE_STATUS_ADDR);
+            break;
+        case APP_CPU_NUM:
+            reg_off = REG_GET_FIELD(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_VIOLATE_STATUS_ADDR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    *addr = (void*)(reg_off > 0 ? (reg_off << I_FAULT_ADDR_SHIFT) + IRAM0_ADDRESS_LOW : 0);
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_iram0_get_monitor_status_register(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_0_IRAM0_PMS_MONITOR_2_REG);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_1_IRAM0_PMS_MONITOR_2_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
+
+    return MEMP_LL_OK;
 }
 
-static inline void esp_memprot_iram0_get_uni_block_sgnf_bits(uint32_t block, uint32_t *write_bit, uint32_t *read_bit, uint32_t *exec_bit)
+
+/* ******************************************************************************************************
+ * *** RTC_FAST ***
+ */
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_intr_source_num(const int core, uint32_t* src_num)
 {
-    HAL_ASSERT(block < IRAM0_TOTAL_UNI_BLOCKS);
+    switch (core) {
+        case PRO_CPU_NUM:
+            *src_num = ETS_CORE0_PIF_PMS_INTR_SOURCE;
+            break;
+        case APP_CPU_NUM:
+            *src_num = ETS_CORE1_PIF_PMS_INTR_SOURCE;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
 
-    switch ( block ) {
-    case IRAM0_UNI_BLOCK_0:
-        *write_bit = DPORT_PMS_PRO_IRAM0_SRAM_0_W;
-        *read_bit = DPORT_PMS_PRO_IRAM0_SRAM_0_R;
-        *exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_0_F;
+//shared PIF PMS lock
+//!!!: use after ALL the constraints have been set
+static inline memprot_ll_err_t memprot_ll_set_pif_constraint_lock(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_get_pif_constraint_lock(const int core, bool* locked)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_0_REG) == 1;
+            break;
+        case APP_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_0_REG) == 1;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_splitaddr_register(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_9_REG);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_9_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
+
+/* ********************************
+ * IRAM0 RTCFAST - SPLIT LINES
+ */
+
+static inline memprot_ll_err_t memprot_ll_set_rtcfast_split_line(const int core, const void *line_addr, const memprot_ll_world_t world)
+{
+    uint32_t addr = (uint32_t)line_addr;
+
+    if (addr < SOC_RTC_IRAM_LOW || addr >= SOC_RTC_IRAM_HIGH) {
+        return MEMP_LL_ERR_SPLIT_ADDR_OUT_OF_RANGE;
+    }
+
+    if (addr % 0x4 != 0) {
+        return MEMP_LL_ERR_SPLIT_ADDR_UNALIGNED;
+    }
+
+    if (core != PRO_CPU_NUM && core != APP_CPU_NUM) {
+        return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    uint32_t mask;
+    uint32_t val;
+
+    switch (world) {
+    case MEMP_LL_WORLD_0:
+        mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_M;
+        val = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_V : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_V;
         break;
-    case IRAM0_UNI_BLOCK_1:
-        *write_bit = DPORT_PMS_PRO_IRAM0_SRAM_1_W;
-        *read_bit = DPORT_PMS_PRO_IRAM0_SRAM_1_R;
-        *exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_1_F;
+    case MEMP_LL_WORLD_1:
+        mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_M;
+        val = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_V : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_V;
         break;
-    case IRAM0_UNI_BLOCK_2:
-        *write_bit = DPORT_PMS_PRO_IRAM0_SRAM_2_W;
-        *read_bit = DPORT_PMS_PRO_IRAM0_SRAM_2_R;
-        *exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_2_F;
+    default:
+        return MEMP_LL_ERR_WORLD_INVALID;
+    }
+
+    uint32_t reg = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_9_REG : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_9_REG;
+
+    CLEAR_PERI_REG_MASK(reg, mask);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((GET_PERI_REG_MASK(reg, mask) == 0) && "Value not stored to required register");
+#endif
+    REG_SET_BITS(reg, mask, (addr >> 2) & val);
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_READ(reg) & mask;
+    HAL_ASSERT((expected == ((addr >> 2) & val)) && "Value not stored to required register");
+#endif
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_get_rtcfast_split_line(const int core, const memprot_ll_world_t world, void **line_addr)
+{
+    if (core != PRO_CPU_NUM && core != APP_CPU_NUM) {
+        return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    uint32_t mask;
+    uint32_t shift;
+
+    switch (world) {
+    case MEMP_LL_WORLD_0:
+        mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_M;
+        shift = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_S : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_0_S;
         break;
-    case IRAM0_UNI_BLOCK_3:
-        *write_bit = DPORT_PMS_PRO_IRAM0_SRAM_3_W;
-        *read_bit = DPORT_PMS_PRO_IRAM0_SRAM_3_R;
-        *exec_bit = DPORT_PMS_PRO_IRAM0_SRAM_3_F;
+    case MEMP_LL_WORLD_1:
+        mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_M;
+        shift = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_S : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_SPLTADDR_WORLD_1_S;
         break;
     default:
-        abort();
+        return MEMP_LL_ERR_WORLD_INVALID;
     }
+
+    uint32_t reg_addr = REG_READ(core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_9_REG : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_9_REG);
+
+    *line_addr = (void *)((((reg_addr & mask) >> shift) << 2) + SOC_RTC_IRAM_LOW);
+
+    return MEMP_LL_OK;
 }
 
-static inline uint32_t esp_memprot_iram0_get_perm_uni_reg(void)
+///////////////////////////////////
+// RTC_FAST - PMS CONFIGURATION
+
+// permission settings
+static inline uint32_t memprot_ll_rtcfast_set_permissions(const bool r, const bool w, const bool x)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_IRAM0_1_REG);
+    uint32_t permissions = 0;
+    if (r) {
+        permissions |= SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_R;
+    }
+    if (w) {
+        permissions |= SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_W;
+    }
+    if (x) {
+        permissions |= SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_F;
+    }
+
+    return permissions;
 }
 
-static inline uint32_t esp_memprot_iram0_get_perm_split_reg(void)
+static inline memprot_ll_err_t memprot_ll_rtcfast_set_pms_area(const int core, const bool r, const bool w, const bool x, const memprot_ll_world_t world, const memprot_ll_area_t area)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_IRAM0_2_REG);
+    if (core != PRO_CPU_NUM && core != APP_CPU_NUM) {
+        return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    uint32_t bits;
+    uint32_t mask;
+
+    switch (world) {
+    case MEMP_LL_WORLD_0: {
+        switch (area) {
+        case MEMP_LL_AREA_LOW:
+            bits = memprot_ll_rtcfast_set_permissions(r, w, x) << (core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_L_S : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_L_S);
+            mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_L_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_L_M;
+            break;
+        case MEMP_LL_AREA_HIGH:
+            bits = memprot_ll_rtcfast_set_permissions(r, w, x) << (core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_H_S : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_H_S);
+            mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_H_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_H_M;
+            break;
+        default:
+            return MEMP_LL_ERR_AREA_INVALID;
+        }
+    } break;
+    case MEMP_LL_WORLD_1: {
+        switch (area) {
+        case MEMP_LL_AREA_LOW:
+            bits = memprot_ll_rtcfast_set_permissions(r, w, x) << (core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L_S : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L_S);
+            mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L_M;
+            break;
+        case MEMP_LL_AREA_HIGH:
+            bits = memprot_ll_rtcfast_set_permissions(r, w, x) << (core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_H_S : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_H_S);
+            mask = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_H_M : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_H_M;
+            break;
+        default:
+            return MEMP_LL_ERR_AREA_INVALID;
+        }
+    } break;
+    default:
+        return MEMP_LL_ERR_WORLD_INVALID;
+    }
+
+    uint32_t reg = core == PRO_CPU_NUM ? SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_10_REG : SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_10_REG;
+
+    CLEAR_PERI_REG_MASK(reg, mask);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((GET_PERI_REG_MASK(reg, mask) == 0) && "Value not stored to required register");
+#endif
+    REG_SET_BITS(reg, bits, mask);
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_READ(reg) & mask;
+    HAL_ASSERT((expected == bits) && "Value not stored to required register");
+#endif
+
+    return MEMP_LL_OK;
 }
 
-static inline void esp_memprot_iram0_set_prot(uint32_t *split_addr, bool lw, bool lr, bool lx, bool hw, bool hr, bool hx)
+static inline void memprot_ll_rtcfast_get_permissions(const uint32_t perms, bool *r, bool *w, bool *x)
 {
-    uint32_t addr = (uint32_t)split_addr;
-    HAL_ASSERT(addr <= IRAM0_SPL_BLOCK_HIGH);
+    *r = perms & SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_R;
+    *w = perms & SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_W;
+    *x = perms & SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_F;
+}
 
-    //find possible split.address in low region blocks
-    int uni_blocks_low = -1;
-    if ( addr >= IRAM0_UNI_BLOCK_0_LOW ) {
-        uni_blocks_low++;
-    }
-    if ( addr >= IRAM0_UNI_BLOCK_1_LOW ) {
-        uni_blocks_low++;
-    }
-    if ( addr >= IRAM0_UNI_BLOCK_2_LOW ) {
-        uni_blocks_low++;
-    }
-    if ( addr >= IRAM0_UNI_BLOCK_3_LOW ) {
-        uni_blocks_low++;
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_pms_area(const int core, bool *r, bool *w, bool *x, const memprot_ll_world_t world, const memprot_ll_area_t area)
+{
+    if (core != PRO_CPU_NUM && core != APP_CPU_NUM) {
+        return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    //unified mgmt settings per block (bits W/R/X: [11:9] bl3, [8:6] bl2, [5:3] bl1, [2:0] bl0)
-    uint32_t write_bit, read_bit, exec_bit;
-    uint32_t uni_block_perm = 0;
+    uint32_t permissions = 0;
 
-    for ( size_t x = 0; x < IRAM0_TOTAL_UNI_BLOCKS; x++ ) {
-        esp_memprot_iram0_get_uni_block_sgnf_bits(x, &write_bit, &read_bit, &exec_bit);
-        if ( x <= uni_blocks_low ) {
-            if (lw) {
-                uni_block_perm |= write_bit;
+    switch (world) {
+    case MEMP_LL_WORLD_0: {
+        switch (area) {
+        case MEMP_LL_AREA_LOW:
+            if (core == PRO_CPU_NUM) {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_L);
+            } else {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L);
             }
-            if (lr) {
-                uni_block_perm |= read_bit;
-            }
-            if (lx) {
-                uni_block_perm |= exec_bit;
-            }
-        } else {
-            if (hw) {
-                uni_block_perm |= write_bit;
+            break;
+        case MEMP_LL_AREA_HIGH:
+            if (core == PRO_CPU_NUM) {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_H);
+            } else {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_0_H);
             }
-            if (hr) {
-                uni_block_perm |= read_bit;
+            break;
+        default:
+            return MEMP_LL_ERR_AREA_INVALID;
+        }
+    } break;
+    case MEMP_LL_WORLD_1: {
+        switch (area) {
+        case MEMP_LL_AREA_LOW:
+            if (core == PRO_CPU_NUM) {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L);
+            } else {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_L);
             }
-            if (hx) {
-                uni_block_perm |= exec_bit;
+            break;
+        case MEMP_LL_AREA_HIGH:
+            if (core == PRO_CPU_NUM) {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_H);
+            } else {
+                permissions = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_10_REG, SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_1_H);
             }
+            break;
+        default:
+            return MEMP_LL_ERR_AREA_INVALID;
         }
+    } break;
+    default:
+        return MEMP_LL_ERR_WORLD_INVALID;
     }
 
-    //if splt.ddr not set yet, do required normalization to make the addr writeble into splt.mgmt cfg register
-    uint32_t reg_split_addr = 0;
+    memprot_ll_rtcfast_get_permissions(permissions, r, w, x);
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_permission_register(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_0_PIF_PMS_CONSTRAIN_10_REG);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_1_PIF_PMS_CONSTRAIN_10_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-    if ( addr >= IRAM0_SPL_BLOCK_LOW ) {
+    return MEMP_LL_OK;
+}
 
-        //split Address must be WORD aligned
-        reg_split_addr = addr >> 2;
-        HAL_ASSERT(addr == (reg_split_addr << 2));
+///////////////////////////////////
+// RTC_FAST - MONITOR
 
-        //use only 17 signf.bits as the cropped parts are constant for whole section (bits [16:0])
-        reg_split_addr = (reg_split_addr << DPORT_PMS_PRO_IRAM0_SRAM_4_SPLTADDR_S) & DPORT_PMS_PRO_IRAM0_SRAM_4_SPLTADDR_M;
+// lock
+static inline memprot_ll_err_t memprot_ll_rtcfast_set_monitor_lock(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_0_PIF_PMS_MONITOR_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_0_PIF_PMS_MONITOR_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_1_PIF_PMS_MONITOR_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_1_PIF_PMS_MONITOR_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    //prepare high & low permission mask (bits: [22:20] high range, [19:17] low range)
-    uint32_t permission_mask = 0;
-    if ( lw ) {
-        permission_mask |= DPORT_PMS_PRO_IRAM0_SRAM_4_L_W;
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_lock(const int core, bool* locked)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_0_PIF_PMS_MONITOR_0_REG) == 1;
+            break;
+        case APP_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_1_PIF_PMS_MONITOR_0_REG) == 1;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( lr ) {
-        permission_mask |= DPORT_PMS_PRO_IRAM0_SRAM_4_L_R;
+
+    return MEMP_LL_OK;
+}
+
+// interrupt enable/clear
+static inline memprot_ll_err_t memprot_ll_rtcfast_set_monitor_en(const int core, const bool enable)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            if (enable) {
+                REG_SET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_EN) > 0) && "Value not stored to required register");
+#endif
+            } else {
+                REG_CLR_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_EN) == 0) && "Value not stored to required register");
+#endif
+            }
+            break;
+        case APP_CPU_NUM:
+            if (enable) {
+                REG_SET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_EN) > 0) && "Value not stored to required register");
+#endif
+            } else {
+                REG_CLR_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_EN) == 0) && "Value not stored to required register");
+#endif
+            }
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( lx ) {
-        permission_mask |= DPORT_PMS_PRO_IRAM0_SRAM_4_L_F;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_en(const int core, bool* enabled)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *enabled = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_EN) > 0;
+            break;
+        case APP_CPU_NUM:
+            *enabled = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_EN) > 0;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( hw ) {
-        permission_mask |= DPORT_PMS_PRO_IRAM0_SRAM_4_H_W;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_intrclr(const int core, bool* cleared)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *cleared = REG_GET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_CLR) > 0;
+            break;
+        case APP_CPU_NUM:
+            *cleared = REG_GET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_CLR) > 0;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( hr ) {
-        permission_mask |= DPORT_PMS_PRO_IRAM0_SRAM_4_H_R;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_set_monitor_intrclr(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_SET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_CLR) > 0) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_SET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_CLR) > 0) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( hx ) {
-        permission_mask |= DPORT_PMS_PRO_IRAM0_SRAM_4_H_F;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_rtcfast_reset_monitor_intrclr(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_CLR_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_CLR) == 0) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_CLR_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_CLR) == 0) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    //write both cfg. registers
-    DPORT_WRITE_PERI_REG( DPORT_PMS_PRO_IRAM0_1_REG, uni_block_perm );
-    DPORT_WRITE_PERI_REG( DPORT_PMS_PRO_IRAM0_2_REG, reg_split_addr | permission_mask );
+    return MEMP_LL_OK;
 }
 
-static inline void esp_memprot_iram0_get_split_sgnf_bits(bool *lw, bool *lr, bool *lx, bool *hw, bool *hr, bool *hx)
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_register(const int core, uint32_t* regval)
 {
-    *lw = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_2_REG, DPORT_PMS_PRO_IRAM0_SRAM_4_L_W );
-    *lr = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_2_REG, DPORT_PMS_PRO_IRAM0_SRAM_4_L_R );
-    *lx = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_2_REG, DPORT_PMS_PRO_IRAM0_SRAM_4_L_F );
-    *hw = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_2_REG, DPORT_PMS_PRO_IRAM0_SRAM_4_H_W );
-    *hr = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_2_REG, DPORT_PMS_PRO_IRAM0_SRAM_4_H_R );
-    *hx = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_IRAM0_2_REG, DPORT_PMS_PRO_IRAM0_SRAM_4_H_F );
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_0_PIF_PMS_MONITOR_1_REG);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_1_PIF_PMS_MONITOR_1_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
 }
 
-/**
- * === DRAM0 ====
- */
+// permission violation status
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_status_intr(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_INTR);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_INTR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-#define DRAM0_TOTAL_UNI_BLOCKS          4
-#define DRAM0_UNI_BLOCK_0               0
-#define DRAM0_UNI_BLOCK_1               1
-#define DRAM0_UNI_BLOCK_2               2
-#define DRAM0_UNI_BLOCK_3               3
+    return MEMP_LL_OK;
+}
 
-#define DRAM0_SPL_BLOCK_BASE            0x3FFB0000
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_status_fault_addr(const int core, void** addr)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *addr = (void*)REG_READ(SENSITIVE_CORE_0_PIF_PMS_MONITOR_3_REG);
+            break;
+        case APP_CPU_NUM:
+            *addr = (void*)REG_READ(SENSITIVE_CORE_1_PIF_PMS_MONITOR_3_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-//unified management (SRAM blocks 0-3)
-#define DRAM0_UNI_BLOCK_0_LOW           0x3FFB0000
-#define DRAM0_UNI_BLOCK_0_HIGH          0x3FFB1FFF
-#define DRAM0_UNI_BLOCK_1_LOW           0x3FFB2000
-#define DRAM0_UNI_BLOCK_1_HIGH          0x3FFB3FFF
-#define DRAM0_UNI_BLOCK_2_LOW           0x3FFB4000
-#define DRAM0_UNI_BLOCK_2_HIGH          0x3FFB5FFF
-#define DRAM0_UNI_BLOCK_3_LOW           0x3FFB6000
-#define DRAM0_UNI_BLOCK_3_HIGH          0x3FFB7FFF
+    return MEMP_LL_OK;
+}
 
-//split management (SRAM blocks 4-21)
-#define DRAM0_SPL_BLOCK_LOW             0x3FFB8000  //block 4 low
-#define DRAM0_SPL_BLOCK_HIGH            0x3FFFFFFF  //block 21 high
-#define DRAM0_SPLTADDR_MIN              0x3FFC0000  //block 6 low - minimum splitting address
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_status_fault_world(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_STATUS_HWORLD);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_STATUS_HWORLD);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
 
-//DRAM0 interrupt status bitmasks
-#define DRAM0_INTR_ST_FAULTADDR_M       0x03FFFFC0  //(bits 25:6 in the reg)
-#define DRAM0_INTR_ST_FAULTADDR_S       0x4         //(bits 21:2 of real address)
-#define DRAM0_INTR_ST_FAULTADDR_HI      0x3FF00000  //(high nonsignificant bits 31:22 of the faulting address - constant)
-#define DRAM0_INTR_ST_OP_RW_BIT         BIT(4)      //read: 0, write: 1
-#define DRAM0_INTR_ST_OP_ATOMIC_BIT     BIT(5)      //non-atomic: 0, atomic: 1
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_status_fault_loadstore(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_STATUS_HPORT_0);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_STATUS_HPORT_0);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
+    return MEMP_LL_OK;
+}
 
-static inline uint32_t esp_memprot_dram0_get_intr_source_num(void)
+static inline memprot_ll_err_t memprot_ll_rtcfast_get_monitor_status_fault_wr(const int core, uint32_t* regval)
 {
-    return ETS_PMS_PRO_DRAM0_ILG_INTR_SOURCE;
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_PIF_PMS_MONITOR_VIOLATE_STATUS_HWRITE);
+            break;
+        case APP_CPU_NUM:
+            *regval =  REG_GET_FIELD(SENSITIVE_CORE_1_PIF_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_PIF_PMS_MONITOR_VIOLATE_STATUS_HWRITE);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
 }
 
-static inline void esp_memprot_dram0_intr_ena(bool enable)
+
+/* ******************************************************************************************************
+ * *** DRAM0 ***
+ * ******************************************************************************************************/
+
+static inline memprot_ll_err_t memprot_ll_dram0_get_intr_source_num(const int core, uint32_t* src_num)
 {
-    if ( enable ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_EN );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_EN );
+    switch (core) {
+        case PRO_CPU_NUM:
+            *src_num = ETS_CORE0_DRAM0_PMS_INTR_SOURCE;
+            break;
+        case APP_CPU_NUM:
+            *src_num = ETS_CORE1_DRAM0_PMS_INTR_SOURCE;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
+
+    return MEMP_LL_OK;
 }
 
-static inline bool esp_memprot_dram0_is_assoc_intr(void)
+///////////////////////////////////
+// DRAM0 - SPLIT LINES
+static inline uint32_t memprot_ll_get_dram0_split_line_main_D_0_regval(void)
 {
-    return DPORT_GET_PERI_REG_MASK(DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_INTR) > 0;
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_4_REG);
 }
 
-static inline void esp_memprot_dram0_clear_intr(void)
+static inline uint32_t memprot_ll_get_dram0_split_line_main_D_1_regval(void)
 {
-    DPORT_SET_PERI_REG_MASK(DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_CLR);
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_5_REG);
 }
 
-static inline uint32_t esp_memprot_dram0_get_intr_ena_bit(void)
+static inline void memprot_ll_prepare_dram0_split_line_regval(const uint32_t addr, uint32_t* regval)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_EN);
+    //set category bits for given split line
+    uint32_t cat[7] = {[0 ... 6]=MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_ABOVE_SA};
+    for (size_t x=0; x<7; x++) {
+        if (addr <= MAP_IRAM_TO_DRAM(sram_rg3_level_hlimits[x])) {
+            cat[x] = MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA;
+            break;
+        } else {
+            cat[x] = MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_BELOW_SA;
+        }
+    }
+
+    //resolve split address' significant bits
+    uint32_t conf_add = ((addr >> I_D_SPLIT_LINE_SHIFT) & SENSITIVE_CORE_X_DRAM0_DMA_SRAM_LINE_0_SPLITADDR_V);
+
+    //write values to required configuration-register
+    constrain_reg_fields_t cfg_reg_val = {
+            .cat0 = cat[0],
+            .cat1 = cat[1],
+            .cat2 = cat[2],
+            .cat3 = cat[3],
+            .cat4 = cat[4],
+            .cat5 = cat[5],
+            .cat6 = cat[6],
+            .splitaddr = conf_add,
+            .reserved = 0
+    };
+
+
+    *regval = cfg_reg_val.val;
 }
 
-static inline uint32_t esp_memprot_dram0_get_intr_on_bit(void)
+static inline memprot_ll_err_t memprot_ll_set_dram0_split_line(const void *line_addr, const uint32_t sensitive_reg)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_INTR);
+    uint32_t addr = (uint32_t)line_addr;
+
+    //sanity check
+    MEMP_LL_CHECK_DRAM_ADDR_IN_RANGE(addr)
+    MEMP_LL_CHECK_SPLIT_ADDR_ALIGNED(addr)
+
+    uint32_t regval;
+    memprot_ll_prepare_dram0_split_line_regval(addr, &regval);
+
+    REG_WRITE(sensitive_reg, regval);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((REG_READ(sensitive_reg) == regval) && "Value not stored to required register");
+#endif
+
+    return MEMP_LL_OK;
 }
 
-static inline uint32_t esp_memprot_dram0_get_intr_clr_bit(void)
+static inline memprot_ll_err_t memprot_ll_set_dram0_split_line_D_0(const void *line_addr)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_DRAM0_3_REG, DPORT_PMS_PRO_DRAM0_ILG_CLR);
+    return memprot_ll_set_dram0_split_line(line_addr, SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_4_REG);
 }
 
-static inline uint32_t esp_memprot_dram0_get_lock_bit(void)
+static inline memprot_ll_err_t memprot_ll_set_dram0_split_line_D_1(const void *line_addr)
 {
-    return DPORT_REG_GET_FIELD(DPORT_PMS_PRO_DRAM0_0_REG, DPORT_PMS_PRO_DRAM0_LOCK);
+    return memprot_ll_set_dram0_split_line(line_addr, SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_5_REG);
 }
 
-static inline void esp_memprot_dram0_get_uni_block_sgnf_bits(uint32_t block, uint32_t *write_bit, uint32_t *read_bit)
+static inline void *memprot_ll_get_dram0_split_line_D_0(void)
 {
-    HAL_ASSERT(block < DRAM0_TOTAL_UNI_BLOCKS);
+    return memprot_ll_get_split_addr_from_reg(REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_4_REG), SOC_DIRAM_DRAM_LOW);
+}
 
-    switch ( block ) {
-    case DRAM0_UNI_BLOCK_0:
-        *write_bit = DPORT_PMS_PRO_DRAM0_SRAM_0_W;
-        *read_bit = DPORT_PMS_PRO_DRAM0_SRAM_0_R;
-        break;
-    case DRAM0_UNI_BLOCK_1:
-        *write_bit = DPORT_PMS_PRO_DRAM0_SRAM_1_W;
-        *read_bit = DPORT_PMS_PRO_DRAM0_SRAM_1_R;
-        break;
-    case DRAM0_UNI_BLOCK_2:
-        *write_bit = DPORT_PMS_PRO_DRAM0_SRAM_2_W;
-        *read_bit = DPORT_PMS_PRO_DRAM0_SRAM_2_R;
-        break;
-    case DRAM0_UNI_BLOCK_3:
-        *write_bit = DPORT_PMS_PRO_DRAM0_SRAM_3_W;
-        *read_bit = DPORT_PMS_PRO_DRAM0_SRAM_3_R;
-        break;
-    default:
-        abort();
-    }
+static inline void *memprot_ll_get_dram0_split_line_D_1(void)
+{
+    return memprot_ll_get_split_addr_from_reg(REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_5_REG), SOC_DIRAM_DRAM_LOW);
 }
 
-static inline void esp_memprot_dram0_set_uni_block_perm(uint32_t block, bool write_perm, bool read_perm)
+static inline uint32_t memprot_ll_get_dram0_split_line_D_0_cat(void)
 {
-    HAL_ASSERT(block < DRAM0_TOTAL_UNI_BLOCKS);
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_4_REG) & 0x3FFF;
+}
 
-    uint32_t write_bit, read_bit;
-    esp_memprot_dram0_get_uni_block_sgnf_bits(block, &write_bit, &read_bit);
+static inline uint32_t memprot_ll_get_dram0_split_line_D_1_cat(void)
+{
+    return REG_READ(SENSITIVE_CORE_X_IRAM0_DRAM0_DMA_SPLIT_LINE_CONSTRAIN_5_REG) & 0x3FFF;
+}
 
-    if ( write_perm ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_DRAM0_1_REG, write_bit );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_DRAM0_1_REG, write_bit );
-    }
+///////////////////////////////////
+// DRAM0 - PMS CONFIGURATION
 
-    if ( read_perm ) {
-        DPORT_SET_PERI_REG_MASK( DPORT_PMS_PRO_DRAM0_1_REG, read_bit );
-    } else {
-        DPORT_CLEAR_PERI_REG_MASK( DPORT_PMS_PRO_DRAM0_1_REG, read_bit );
-    }
+// lock
+static inline void memprot_ll_dram0_set_pms_lock(void)
+{
+    REG_WRITE(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+    HAL_ASSERT((REG_READ(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_0_REG) == 1) && "Value not stored to required register");
+#endif
 }
 
-static inline uint32_t esp_memprot_dram0_get_uni_block_read_bit(uint32_t block)
+static inline bool memprot_ll_dram0_get_pms_lock(void)
 {
-    HAL_ASSERT(block < DRAM0_TOTAL_UNI_BLOCKS);
+    return REG_READ(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_0_REG) == 1;
+}
 
-    switch ( block ) {
-    case DRAM0_UNI_BLOCK_0:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_0_R );
-    case DRAM0_UNI_BLOCK_1:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_1_R );
-    case DRAM0_UNI_BLOCK_2:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_2_R );
-    case DRAM0_UNI_BLOCK_3:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_3_R );
-    default:
-        abort();
+// permission settings
+static inline uint32_t memprot_ll_dram0_set_permissions(const bool r, const bool w)
+{
+    uint32_t permissions = 0;
+    if (r) {
+        permissions |= SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_R;
     }
+    if (w) {
+        permissions |= SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_W;
+    }
+
+    return permissions;
 }
 
-static inline uint32_t esp_memprot_dram0_get_uni_block_write_bit(uint32_t block)
+static inline void memprot_ll_dram0_set_pms_area_0(const bool r, const bool w)
 {
-    HAL_ASSERT(block < DRAM0_TOTAL_UNI_BLOCKS);
-
-    switch ( block ) {
-    case DRAM0_UNI_BLOCK_0:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_0_W );
-    case DRAM0_UNI_BLOCK_1:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_1_W );
-    case DRAM0_UNI_BLOCK_2:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_2_W );
-    case DRAM0_UNI_BLOCK_3:
-        return DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_3_W );
-    default:
-        abort();
-    }
+    REG_SET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_0, memprot_ll_dram0_set_permissions(r, w));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_0);
+    HAL_ASSERT((expected == memprot_ll_dram0_set_permissions(r, w)) && "Value not stored to required register");
+#endif
 }
 
-static inline uint32_t esp_memprot_dram0_get_lock_reg(void)
+static inline void memprot_ll_dram0_set_pms_area_1(const bool r, const bool w)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_DRAM0_0_REG);
+    REG_SET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_1, memprot_ll_dram0_set_permissions(r, w));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_1);
+    HAL_ASSERT((expected == memprot_ll_dram0_set_permissions(r, w)) && "Value not stored to required register");
+#endif
 }
 
-//lock resets automatically on CPU restart
-static inline void esp_memprot_dram0_set_lock(void)
+static inline void memprot_ll_dram0_set_pms_area_2(const bool r, const bool w)
 {
-    DPORT_WRITE_PERI_REG( DPORT_PMS_PRO_DRAM0_0_REG, DPORT_PMS_PRO_DRAM0_LOCK);
+    REG_SET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_2, memprot_ll_dram0_set_permissions(r, w));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_2);
+    HAL_ASSERT((expected == memprot_ll_dram0_set_permissions(r, w)) && "Value not stored to required register");
+#endif
 }
 
-static inline uint32_t esp_memprot_dram0_get_perm_reg(void)
+static inline void memprot_ll_dram0_set_pms_area_3(const bool r, const bool w)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_DRAM0_1_REG);
+    REG_SET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_3, memprot_ll_dram0_set_permissions(r, w));
+#ifdef PMS_DEBUG_ASSERTIONS
+    uint32_t expected = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_3);
+    HAL_ASSERT((expected == memprot_ll_dram0_set_permissions(r, w)) && "Value not stored to required register");
+#endif
 }
 
-static inline uint32_t esp_memprot_dram0_get_ena_reg(void)
+static inline void memprot_ll_dram0_get_permissions(const uint32_t perms, bool *r, bool *w )
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_DRAM0_3_REG);
+    *r = perms & SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_R;
+    *w = perms & SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_W;
 }
 
-static inline uint32_t esp_memprot_dram0_get_fault_reg(void)
+static inline void memprot_ll_dram0_get_pms_area_0(bool *r, bool *w)
 {
-    return DPORT_READ_PERI_REG(DPORT_PMS_PRO_DRAM0_4_REG);
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_0);
+    memprot_ll_dram0_get_permissions(permissions, r, w);
 }
 
-static inline void esp_memprot_dram0_get_fault_status(uint32_t **faulting_address, uint32_t *op_type, uint32_t *op_subtype)
+static inline void memprot_ll_dram0_get_pms_area_1(bool *r, bool *w)
 {
-    uint32_t status_bits = esp_memprot_dram0_get_fault_reg();
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_1);
+    memprot_ll_dram0_get_permissions(permissions, r, w);
+}
 
-    uint32_t fault_addr = (status_bits & DRAM0_INTR_ST_FAULTADDR_M) >> DRAM0_INTR_ST_FAULTADDR_S;
-    *faulting_address = (uint32_t *)(fault_addr | DRAM0_INTR_ST_FAULTADDR_HI);
+static inline void memprot_ll_dram0_get_pms_area_2(bool *r, bool *w)
+{
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_2);
+    memprot_ll_dram0_get_permissions(permissions, r, w);
+}
 
-    *op_type = (uint32_t)status_bits & DRAM0_INTR_ST_OP_RW_BIT;
-    *op_subtype = (uint32_t)status_bits & DRAM0_INTR_ST_OP_ATOMIC_BIT;
+static inline void memprot_ll_dram0_get_pms_area_3(bool *r, bool *w)
+{
+    uint32_t permissions = REG_GET_FIELD(SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_1_REG, SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_0_PMS_3);
+    memprot_ll_dram0_get_permissions(permissions, r, w);
 }
 
-static inline void esp_memprot_dram0_set_prot(uint32_t *split_addr, bool lw, bool lr, bool hw, bool hr)
+
+///////////////////////////////////
+// DRAM0 - MONITOR
+
+// lock
+static inline memprot_ll_err_t memprot_ll_dram0_set_monitor_lock(const int core)
 {
-    uint32_t addr = (uint32_t)split_addr;
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_WRITE(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_0_REG, 1);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_READ(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_0_REG) == 1) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-    //low boundary check provided by LD script. see comment in esp_memprot_iram0_set_prot()
-    HAL_ASSERT(addr <= DRAM0_SPL_BLOCK_HIGH);
+    return MEMP_LL_OK;
+}
 
-    //set low region
-    int uni_blocks_low = -1;
-    if ( addr >= DRAM0_UNI_BLOCK_0_LOW ) {
-        uni_blocks_low++;
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_lock(const int core, bool* locked)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_0_REG) == 1;
+            break;
+        case APP_CPU_NUM:
+            *locked = REG_READ(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_0_REG) == 1;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( addr >= DRAM0_UNI_BLOCK_1_LOW ) {
-        uni_blocks_low++;
+
+    return MEMP_LL_OK;
+}
+
+// interrupt enable/clear
+static inline memprot_ll_err_t memprot_ll_dram0_set_monitor_en(const int core, const bool enable)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            if (enable) {
+                REG_SET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_EN) > 0) && "Value not stored to required register");
+#endif
+            } else {
+                REG_CLR_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_EN) == 0) && "Value not stored to required register");
+#endif
+            }
+            break;
+        case APP_CPU_NUM:
+            if (enable) {
+                REG_SET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_EN) > 0) && "Value not stored to required register");
+#endif
+            } else {
+                REG_CLR_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_EN);
+#ifdef PMS_DEBUG_ASSERTIONS
+                HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_EN) == 0) && "Value not stored to required register");
+#endif
+            }
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( addr >= DRAM0_UNI_BLOCK_2_LOW ) {
-        uni_blocks_low++;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_en(const int core, bool* enabled)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *enabled = REG_GET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_EN) > 0;
+            break;
+        case APP_CPU_NUM:
+            *enabled = REG_GET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_EN) > 0;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if ( addr >= DRAM0_UNI_BLOCK_3_LOW ) {
-        uni_blocks_low++;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_dram0_set_monitor_intrclr(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_SET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_CLR) > 0) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_SET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_CLR) > 0) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    //set unified mgmt region
-    uint32_t write_bit, read_bit, uni_block_perm = 0;
-    for ( size_t x = 0; x < DRAM0_TOTAL_UNI_BLOCKS; x++ ) {
-        esp_memprot_dram0_get_uni_block_sgnf_bits(x, &write_bit, &read_bit);
-        if ( x <= uni_blocks_low ) {
-            if (lw) {
-                uni_block_perm |= write_bit;
-            }
-            if (lr) {
-                uni_block_perm |= read_bit;
-            }
-        } else {
-            if (hw) {
-                uni_block_perm |= write_bit;
-            }
-            if (hr) {
-                uni_block_perm |= read_bit;
-            }
-        }
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_dram0_reset_monitor_intrclr(const int core)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            REG_CLR_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_CLR) == 0) && "Value not stored to required register");
+#endif
+            break;
+        case APP_CPU_NUM:
+            REG_CLR_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_CLR);
+#ifdef PMS_DEBUG_ASSERTIONS
+            HAL_ASSERT((REG_GET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_CLR) == 0) && "Value not stored to required register");
+#endif
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    //check split address is WORD aligned
-    uint32_t reg_split_addr = addr >> 2;
-    HAL_ASSERT(addr == (reg_split_addr << 2));
+    return MEMP_LL_OK;
+}
 
-    //shift aligned split address to proper bit offset
-    reg_split_addr = (reg_split_addr << DPORT_PMS_PRO_DRAM0_SRAM_4_SPLTADDR_S) & DPORT_PMS_PRO_DRAM0_SRAM_4_SPLTADDR_M;
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_intrclr(const int core, bool* cleared)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *cleared = REG_GET_BIT(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_CLR) > 0;
+            break;
+        case APP_CPU_NUM:
+            *cleared = REG_GET_BIT(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_CLR) > 0;
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
 
-    //prepare high & low permission mask
-    uint32_t permission_mask = 0;
-    if (lw) {
-        permission_mask |= DPORT_PMS_PRO_DRAM0_SRAM_4_L_W;
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_enable_register(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_1_REG);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_READ(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_1_REG);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if (lr) {
-        permission_mask |= DPORT_PMS_PRO_DRAM0_SRAM_4_L_R;
+
+    return MEMP_LL_OK;
+}
+
+// permission violation status
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_status_intr(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_INTR);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_INTR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if (hw) {
-        permission_mask |= DPORT_PMS_PRO_DRAM0_SRAM_4_H_W;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_status_fault_world(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_STATUS_WORLD);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_STATUS_WORLD);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
-    if (hr) {
-        permission_mask |= DPORT_PMS_PRO_DRAM0_SRAM_4_H_R;
+
+    return MEMP_LL_OK;
+}
+
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_status_fault_addr(const int core, void** addr)
+{
+    uint32_t reg_off;
+
+    switch (core) {
+        case PRO_CPU_NUM:
+            reg_off = REG_GET_FIELD(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_STATUS_ADDR);
+            break;
+        case APP_CPU_NUM:
+            reg_off = REG_GET_FIELD(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_STATUS_ADDR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
     }
 
-    //write configuration to DPORT_PMS_PRO_DRAM0_1_REG
-    DPORT_WRITE_PERI_REG(DPORT_PMS_PRO_DRAM0_1_REG, reg_split_addr | permission_mask | uni_block_perm);
+    *addr = (void*)(reg_off > 0 ? (reg_off << D_FAULT_ADDR_SHIFT) + DRAM0_ADDRESS_LOW : 0);
+
+    return MEMP_LL_OK;
 }
 
-static inline void esp_memprot_dram0_get_split_sgnf_bits(bool *lw, bool *lr, bool *hw, bool *hr)
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_status_fault_wr(const int core, uint32_t* regval)
 {
-    *lw = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_4_L_W );
-    *lr = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_4_L_R );
-    *hw = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_4_H_W );
-    *hr = DPORT_REG_GET_FIELD( DPORT_PMS_PRO_DRAM0_1_REG, DPORT_PMS_PRO_DRAM0_SRAM_4_H_R );
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_3_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_STATUS_WR);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_3_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_STATUS_WR);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
 }
 
-#endif
+static inline memprot_ll_err_t memprot_ll_dram0_get_monitor_status_fault_byte_en(const int core, uint32_t* regval)
+{
+    switch (core) {
+        case PRO_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_0_DRAM0_PMS_MONITOR_VIOLATE_STATUS_BYTEEN);
+            break;
+        case APP_CPU_NUM:
+            *regval = REG_GET_FIELD(SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_2_REG, SENSITIVE_CORE_1_DRAM0_PMS_MONITOR_VIOLATE_STATUS_BYTEEN);
+            break;
+        default:
+            return MEMP_LL_ERR_CORE_INVALID;
+    }
+
+    return MEMP_LL_OK;
+}
 
 #ifdef __cplusplus
 }
diff --git a/components/hal/include/hal/memprot_types.h b/components/hal/include/hal/memprot_types.h
index 15e3c3959a..b335519058 100644
--- a/components/hal/include/hal/memprot_types.h
+++ b/components/hal/include/hal/memprot_types.h
@@ -6,6 +6,9 @@
 
 #pragma once
 
+#include "soc/soc.h"
+#include "soc/memprot_defs.h"
+
 #ifdef __cplusplus
 extern "C" {
 #endif
@@ -16,13 +19,19 @@ extern "C" {
  */
 typedef enum {
     MEMP_LL_OK = 0,
+#ifndef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
     MEMP_LL_FAIL = 1,
+#endif
     MEMP_LL_ERR_SPLIT_ADDR_OUT_OF_RANGE = 2,
     MEMP_LL_ERR_SPLIT_ADDR_INVALID = 2,         /* temporary duplicate for S2 builds */
     MEMP_LL_ERR_SPLIT_ADDR_UNALIGNED = 3,
     MEMP_LL_ERR_UNI_BLOCK_INVALID = 4,
     MEMP_LL_ERR_AREA_INVALID = 5,
-    MEMP_LL_ERR_WORLD_INVALID = 6
+    MEMP_LL_ERR_WORLD_INVALID = 6,
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    MEMP_LL_ERR_CORE_INVALID = 7,
+    MEMP_LL_FAIL = -1,
+#endif
 } memprot_ll_err_t;
 
 /**
@@ -45,6 +54,19 @@ typedef enum {
     MEMP_LL_AREA_HIGH = 2
 } memprot_ll_area_t;
 
+//auxiliary macros & defines
+#define SOC_I_D_OFFSET (SOC_DIRAM_IRAM_LOW - SOC_DIRAM_DRAM_LOW)
+#define MAP_DRAM_TO_IRAM(addr) (addr + SOC_I_D_OFFSET)
+#define MAP_IRAM_TO_DRAM(addr) (addr - SOC_I_D_OFFSET)
+
+#define MEMP_LL_CHECK_IRAM_ADDR_IN_RANGE(x) if (x < SOC_DIRAM_IRAM_LOW || x >= SOC_DIRAM_IRAM_HIGH) { return MEMP_LL_ERR_SPLIT_ADDR_OUT_OF_RANGE; }
+#define MEMP_LL_CHECK_DRAM_ADDR_IN_RANGE(x) if (x < SOC_DIRAM_DRAM_LOW || x >= SOC_DIRAM_DRAM_HIGH) { return MEMP_LL_ERR_SPLIT_ADDR_OUT_OF_RANGE; }
+#define MEMP_LL_CHECK_SPLIT_ADDR_ALIGNED(x) if (x % I_D_SPLIT_LINE_ALIGN != 0) { return MEMP_LL_ERR_SPLIT_ADDR_UNALIGNED; }
+
+#define MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_BELOW_SA  0x0 //0b00
+#define MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_EQUAL_SA  0x2 //0b10
+#define MEMP_LL_CORE_X_IRAM0_DRAM0_DMA_SRAM_CATEGORY_BITS_ABOVE_SA  0x3 //0b11
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/components/hal/interrupt_controller_hal.c b/components/hal/interrupt_controller_hal.c
index f7e815beff..5335d3003d 100644
--- a/components/hal/interrupt_controller_hal.c
+++ b/components/hal/interrupt_controller_hal.c
@@ -22,7 +22,11 @@ static bool is_interrupt_number_reserved(int interrupt_number)
 {
     // Workaround to reserve interrupt number 1 for Wi-Fi, 5,8 for Bluetooth, 6 for "permanently disabled interrupt"
     // [TODO: IDF-2465]
+#ifdef CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    const uint32_t reserved = BIT(1) | BIT(2) | BIT(5) | BIT(6) | BIT(8);
+#else
     const uint32_t reserved = BIT(1) | BIT(5) | BIT(6) | BIT(8);
+#endif
     if (reserved & BIT(interrupt_number)) {
         return true;
     }
diff --git a/components/heap/port/esp32c3/memory_layout.c b/components/heap/port/esp32c3/memory_layout.c
index 3ca3272417..ff5266d5f1 100644
--- a/components/heap/port/esp32c3/memory_layout.c
+++ b/components/heap/port/esp32c3/memory_layout.c
@@ -61,7 +61,7 @@ const size_t soc_memory_type_count = sizeof(soc_memory_types) / sizeof(soc_memor
  *       this list should always be sorted from low to high by start address.
  *
  */
-const soc_memory_region_t soc_memory_regions[] = {
+__attribute__((weak)) const soc_memory_region_t soc_memory_regions[] = {
     { 0x3FC80000, 0x20000, SOC_MEMORY_TYPE_DEFAULT, 0x40380000}, //Block 4,  can be remapped to ROM, can be used as trace memory
     { 0x3FCA0000, 0x20000, SOC_MEMORY_TYPE_DEFAULT, 0x403A0000}, //Block 5,  can be remapped to ROM, can be used as trace memory
     { 0x3FCC0000, 0x20000, 1, 0x403C0000}, //Block 9,  can be used as trace memory
@@ -70,7 +70,7 @@ const soc_memory_region_t soc_memory_regions[] = {
 #endif
 };
 
-const size_t soc_memory_region_count = sizeof(soc_memory_regions) / sizeof(soc_memory_region_t);
+__attribute__((weak)) const size_t soc_memory_region_count = sizeof(soc_memory_regions) / sizeof(soc_memory_region_t);
 
 
 extern int _data_start, _heap_start, _iram_start, _iram_end, _rtc_force_slow_end;
diff --git a/components/heap/port/esp32s3/memory_layout.c b/components/heap/port/esp32s3/memory_layout.c
index ae592a2da6..006dc2a9c9 100644
--- a/components/heap/port/esp32s3/memory_layout.c
+++ b/components/heap/port/esp32s3/memory_layout.c
@@ -54,7 +54,7 @@ const size_t soc_memory_type_count = sizeof(soc_memory_types) / sizeof(soc_memor
  *       this list should always be sorted from low to high by start address.
  *
  */
-const soc_memory_region_t soc_memory_regions[] = {
+__attribute__((weak)) const soc_memory_region_t soc_memory_regions[] = {
 #ifdef CONFIG_SPIRAM
     { SOC_EXTRAM_DATA_LOW, SOC_EXTRAM_DATA_SIZE, 4, 0}, //SPI SRAM, if available
 #endif
@@ -72,14 +72,14 @@ const soc_memory_region_t soc_memory_regions[] = {
     { 0x3FCF0000, 0x8000,  0, 0},          //Level 9, DRAM
 #endif
 #if CONFIG_ESP32S3_DATA_CACHE_16KB
-    { 0x3C000000, 0x4000,  5, 0}
+    { 0x3C000000, 0x4000,  5, 0},
 #endif
 #ifdef CONFIG_ESP_SYSTEM_ALLOW_RTC_FAST_MEM_AS_HEAP
     { 0x600fe000, 0x2000,  6, 0}, //Fast RTC memory
 #endif
 };
 
-const size_t soc_memory_region_count = sizeof(soc_memory_regions) / sizeof(soc_memory_region_t);
+__attribute__((weak)) const size_t soc_memory_region_count = sizeof(soc_memory_regions) / sizeof(soc_memory_region_t);
 
 extern int _data_start, _heap_start, _iram_start, _iram_end, _rtc_force_fast_end, _rtc_noinit_end; // defined in sections.ld.in
 
diff --git a/components/partition_table/gen_esp32part.py b/components/partition_table/gen_esp32part.py
index ba6ba6c5da..1a554a74ce 100755
--- a/components/partition_table/gen_esp32part.py
+++ b/components/partition_table/gen_esp32part.py
@@ -27,6 +27,8 @@ PARTITION_TABLE_SIZE  = 0x1000  # Size of partition table
 
 MIN_PARTITION_SUBTYPE_APP_OTA = 0x10
 NUM_PARTITION_SUBTYPE_APP_OTA = 16
+MIN_PARTITION_SUBTYPE_USER_APP_OTA = 0x40
+NUM_PARTITION_SUBTYPE_USER_APP_OTA = 2
 
 __version__ = '1.2'
 
@@ -64,6 +66,7 @@ SUBTYPES = {
         'nvs_keys': 0x04,
         'efuse': 0x05,
         'undefined': 0x06,
+        'user_ota': 0x50,
         'esphttpd': 0x80,
         'fat': 0x81,
         'spiffs': 0x82,
@@ -311,6 +314,10 @@ class PartitionDefinition(object):
     for ota_slot in range(NUM_PARTITION_SUBTYPE_APP_OTA):
         SUBTYPES[TYPES['app']]['ota_%d' % ota_slot] = MIN_PARTITION_SUBTYPE_APP_OTA + ota_slot
 
+    # add subtypes for the 2 User OTA slot values ("ota_XX, etc.")
+    for ota_slot in range(NUM_PARTITION_SUBTYPE_USER_APP_OTA):
+        SUBTYPES[TYPES['app']]['user_%d' % ota_slot] = MIN_PARTITION_SUBTYPE_USER_APP_OTA + ota_slot
+
     def __init__(self):
         self.name = ''
         self.type = None
diff --git a/components/riscv/vectors.S b/components/riscv/vectors.S
index 89bf09e1e9..b44ed2b23c 100644
--- a/components/riscv/vectors.S
+++ b/components/riscv/vectors.S
@@ -16,9 +16,26 @@
 #include "riscv/rvruntime-frames.h"
 #include "soc/soc_caps.h"
 #include "sdkconfig.h"
-
-
-    .equ SAVE_REGS, 32
+#include "soc/sensitive_reg.h"
+#include "soc/world_controller_reg.h"
+#include "soc/extmem_reg.h"
+
+#define W1_EXCEPTION_MAGIC  21
+#define EXCCAUSE_ECALL  11
+
+/*
+ * uxTCBNumber and uxTaskNumber members are added in TCB structure when
+ * FreeRTOS Trace facility is enabled. WORLD offset is changed by 8 bytes
+ * because both members are 4 bytes in size.
+ */
+#ifdef CONFIG_FREERTOS_USE_TRACE_FACILITY
+#define WORLD_OFFSET    (0x4c + CONFIG_FREERTOS_MAX_TASK_NAME_LEN + 3 + 8)&~3
+#else
+#define WORLD_OFFSET    (0x4c + CONFIG_FREERTOS_MAX_TASK_NAME_LEN + 3)&~3
+#endif
+
+    /* Save CSRs when servicing interrupts */
+    .equ SAVE_REGS, 40
     .equ CONTEXT_SIZE, (SAVE_REGS * 4)
     .equ panic_from_exception, xt_unhandled_exception
     .equ panic_from_isr, panicHandler
@@ -65,6 +82,35 @@
     sw   t0, RV_STK_MEPC(sp)
 .endm
 
+.macro save_world
+    mv      t0, zero
+    csrr    t1, mcause
+    li      t2, 0x80000000
+    bleu    t1, t2, _from_exception
+
+    li      t2, 0x7fffffff
+    and     t0, t1, t2
+_from_exception:
+    /* t0 contains the mcause that is also the STATUSTABLE entry */
+    la      t1, WORLD_CONTROL_CORE_X_STATUSTABLE(0,0)
+    slli    t0, t0, 2
+    add     t2, t1, t0
+    lw      t3, 0x0(t2)
+    /* Zero out the STATUSTABLE contents and store the WORLD */
+    sw      zero, 0x0(t2)
+    andi    t3, t3, 1
+
+    la      t4, pxCurrentTCB
+    lw      t5, 0x00(t4)
+    sw      t3, WORLD_OFFSET(t5)
+
+    /* Set WORLD controller MIE to track changes in STATUSTABLE */
+    la      t0, WORLD_CONTROL_CORE_X_MSTATUS_MIE(0)
+    li      t1, 1
+    sw      t1, 0x0(t0)
+    fence
+.endm
+
 /* Restore the general purpose registers (excluding gp) from the context on
  * the stack. The context is then deallocated. The default size is CONTEXT_SIZE
  * but it can be overriden. */
@@ -106,6 +152,29 @@
     csrw    mepc, t0
 .endm
 
+.macro restore_world
+    la      t0, pxCurrentTCB
+    lw      t0, 0x00(t0)
+    lw      t0, WORLD_OFFSET(t0)
+    beq     t0, zero, skip_restore_world
+
+    /* Prepare WORLD controller for switch */
+    li      t1, 2
+    la      t2, WORLD_CONTROL_CORE_X_WORLD_PREPARE(0)
+    sw      t1, 0x0(t2)
+
+    /* Set TRIGGER_ADDR to the return address; held by MEPC */
+    lw      t1, RV_STK_MEPC(sp)
+    la      t2, WORLD_CONTROL_CORE_X_WORLD_TRIGGER_ADDR(0)
+    sw      t1, 0x0(t2)
+
+    li      t1, 1
+    la      t2, WORLD_CONTROL_CORE_X_WORLD_UPDATE(0)
+    sw      t1, 0x0(t2)
+skip_restore_world:
+    fence
+.endm
+
     .global rtos_int_enter
     .global rtos_int_exit
     .global _global_interrupt_handler
@@ -148,6 +217,35 @@ _vector_table:
     /* Exception handler.*/
     .type _panic_handler, @function
 _panic_handler:
+
+#if CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    csrw    mscratch, t0
+
+    /* If exception caused by ecall, skip other W1 checks */
+    csrr    t0, mcause
+    xori    t0, t0, EXCCAUSE_ECALL
+    beq     t0, zero, w0_exception
+
+    /* Check if the exception occurred in W1 environment,
+     * if so, delegate to _interrupt_handler
+     */
+    la      t0, WORLD_CONTROL_CORE_X_STATUSTABLE(0,0)
+    lw      t0, 0x0(t0)
+    andi    t0, t0, 1
+    beq     t0, zero, w0_exception
+    csrr    t0, mscratch
+
+    /* Use mscratch temporarily to notify _interrupt_handler about the W1 exception
+     * Storing a number (21, 0b10101) in mscratch
+     */
+    csrrwi  zero, mscratch, W1_EXCEPTION_MAGIC
+
+    j       _interrupt_handler
+
+w0_exception:
+    csrr    t0, mscratch
+#endif
+
     /* Allocate space on the stack and store general purpose registers */
     save_general_regs RV_STK_FRMSZ
 
@@ -159,6 +257,22 @@ _panic_handler:
 
     /* Save CSRs */
     sw    t0, RV_STK_SP(sp)
+
+#if CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    /* If exception caused by ECALL, delegate to __ecall_handler and store
+     * privileged registers in kernel stack
+     */
+    csrr    t2, mcause
+    li      t3, EXCCAUSE_ECALL
+    bne     t2, t3, _skip_ecall
+
+    .global __ecall_handler
+
+    // Need to be defined by the application
+    call    __ecall_handler             // Should not return
+
+_skip_ecall:
+#endif
     csrr  t0, mepc
     sw    t0, RV_STK_MEPC(sp)
     csrr  t0, mstatus
@@ -221,7 +335,43 @@ _interrupt_handler:
      * the interrupt happened. */
     save_general_regs
     save_mepc
+#if CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    save_world
+
+    /* Save CSRs */
+    sw    gp, RV_STK_GP(sp)
+
+    addi  t0, sp, CONTEXT_SIZE /* restore sp with the value when trap happened */
 
+    sw    t0, RV_STK_SP(sp)
+    csrr  t0, mstatus
+    sw    t0, RV_STK_MSTATUS(sp)
+    csrr  t0, mtvec
+    sw    t0, RV_STK_MTVEC(sp)
+    csrr  t0, mcause
+    sw    t0, RV_STK_MCAUSE(sp)
+    csrr  t0, mtval
+    sw    t0, RV_STK_MTVAL(sp)
+    csrr  t0, mhartid
+    sw    t0, RV_STK_MHARTID(sp)
+
+    /* Check if we arrive here because of exception in user space */
+    csrr    t0, mscratch
+    li      t1, W1_EXCEPTION_MAGIC
+    bne     t0, t1, 1f
+
+    /* It is indeed from W1 exception.
+     * Set the mcause to 2 (interrupt reserved for W1 exception)
+     * The actual mcause is already stored on the stack
+     */
+    csrrwi  zero, mcause, 2
+
+    /* Clear mscratch CSR */
+    csrw   mscratch, zero
+
+    fence
+1:
+#else
     /* Though it is not necessary we save GP and SP here.
      * SP is necessary to help GDB to properly unwind
      * the backtrace of threads preempted by interrupts (OS tick etc.).
@@ -232,6 +382,7 @@ _interrupt_handler:
     addi  t0, sp, CONTEXT_SIZE /* restore sp with the value when interrupt happened */
     /* Save SP */
     sw    t0, RV_STK_SP(sp)
+#endif
 
     /* Before doing anythig preserve the stack pointer */
     /* It will be saved in current TCB, if needed */
@@ -308,6 +459,9 @@ _interrupt_handler:
     /* restore the rest of the registers */
     csrw    mcause, s1
     csrw    mstatus, s2
+#if CONFIG_ESP_PRIVILEGE_SEPARATION_ENABLE
+    restore_world
+#endif
     restore_mepc
     restore_general_regs
 
diff --git a/components/soc/esp32c3/include/soc/memprot_defs.h b/components/soc/esp32c3/include/soc/memprot_defs.h
index b08e1f83b4..e90e6faaf3 100644
--- a/components/soc/esp32c3/include/soc/memprot_defs.h
+++ b/components/soc/esp32c3/include/soc/memprot_defs.h
@@ -35,6 +35,11 @@ typedef union {
 
 #define DRAM_SRAM_START             0x3FC7C000
 
+/*
+ * Commenting the following definition as they are defined in hal/memprot_types.h.
+ * For S3 memprot support, we have cherry-picked a commit from the next release
+ */
+/*
 #ifndef MAP_DRAM_TO_IRAM
 #define MAP_DRAM_TO_IRAM(addr)       (addr - DRAM_SRAM_START + SOC_IRAM_LOW)
 #endif
@@ -42,6 +47,7 @@ typedef union {
 #ifndef MAP_IRAM_TO_DRAM
 #define MAP_IRAM_TO_DRAM(addr)       (addr - SOC_IRAM_LOW + DRAM_SRAM_START)
 #endif
+*/
 
 //IRAM0
 
diff --git a/components/soc/esp32c3/include/soc/world_controller_reg.h b/components/soc/esp32c3/include/soc/world_controller_reg.h
new file mode 100644
index 0000000000..57eeb1e2bd
--- /dev/null
+++ b/components/soc/esp32c3/include/soc/world_controller_reg.h
@@ -0,0 +1,66 @@
+// Copyright 2022 Espressif Systems (Shanghai) PTE LTD
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#pragma once
+
+#define WORLD_CONTROL_BASE                                      0x600D0000
+#define WORLD_CONTROL_CORE_X_BASE(i)                            ((WORLD_CONTROL_BASE) + 0x400*(i))
+
+#define WORLD_CONTROL_CORE_X_MTVEC_BASE(i)                      (WORLD_CONTROL_CORE_X_BASE(i) + 0x000)
+#define WORLD_CONTROL_CORE_X_MSTATUS_MIE(i)                     (WORLD_CONTROL_CORE_X_BASE(i) + 0x004)
+#define WORLD_CONTROL_CORE_X_ENTRY_CHECK(i)                     (WORLD_CONTROL_CORE_X_BASE(i) + 0x008)
+#define WORLD_CONTROL_CORE_X_WORLD_CAHNGE_OPT(i)                (WORLD_CONTROL_CORE_X_BASE(i) + 0x020)
+#define WORLD_CONTROL_CORE_X_MESSAGE_ADDR(i)                    (WORLD_CONTROL_CORE_X_BASE(i) + 0x024)
+#define WORLD_CONTROL_CORE_X_MESSAGE_MAX(i)                     (WORLD_CONTROL_CORE_X_BASE(i) + 0x028)
+#define WORLD_CONTROL_CORE_X_STATUSTABLE(i, j)                  (WORLD_CONTROL_CORE_X_BASE(i) + 0x040 + 0x4*(j))
+#define WORLD_CONTROL_CORE_X_STATUSTABLE_CURRENT(i)             (WORLD_CONTROL_CORE_X_BASE(i) + 0x0E0)
+#define WORLD_CONTROL_CORE_X_MESSAGE_PHASE(i)                   (WORLD_CONTROL_CORE_X_BASE(i) + 0x0E4)
+#define WORLD_CONTROL_CORE_X_WORLD_TRIGGER_ADDR(i)              (WORLD_CONTROL_CORE_X_BASE(i) + 0x140)
+#define WORLD_CONTROL_CORE_X_WORLD_PREPARE(i)                   (WORLD_CONTROL_CORE_X_BASE(i) + 0x144)
+#define WORLD_CONTROL_CORE_X_WORLD_UPDATE(i)                    (WORLD_CONTROL_CORE_X_BASE(i) + 0x148)
+#define WORLD_CONTROL_CORE_X_WORLD_CANCEL(i)                    (WORLD_CONTROL_CORE_X_BASE(i) + 0x14c)
+#define WORLD_CONTROL_CORE_X_WORLD_IRAM0(i)                     (WORLD_CONTROL_CORE_X_BASE(i) + 0x150)
+#define WORLD_CONTROL_CORE_X_WORLD_DRAM0_PIF(i)                 (WORLD_CONTROL_CORE_X_BASE(i) + 0x154)
+#define WORLD_CONTROL_CORE_X_WORLD_PHASE(i)                     (WORLD_CONTROL_CORE_X_BASE(i) + 0x158)
+#define WORLD_CONTROL_CORE_X_NMI_MASK_ENABLE(i)                 (WORLD_CONTROL_CORE_X_BASE(i) + 0x180)
+#define WORLD_CONTROL_CORE_X_NMI_MASK_TRIGGER_ADDR(i)           (WORLD_CONTROL_CORE_X_BASE(i) + 0x184)
+#define WORLD_CONTROL_CORE_X_NMI_MASK_DISABLE(i)                (WORLD_CONTROL_CORE_X_BASE(i) + 0x188)
+#define WORLD_CONTROL_CORE_X_NMI_MASK_CANCEL(i)                 (WORLD_CONTROL_CORE_X_BASE(i) + 0x18c)
+#define WORLD_CONTROL_CORE_X_NMI_MASK(i)                        (WORLD_CONTROL_CORE_X_BASE(i) + 0x190)
+#define WORLD_CONTROL_CORE_X_NMI_MASK_PHASE(i)                  (WORLD_CONTROL_CORE_X_BASE(i) + 0x194)
+
+#define WORLD_CONTROLLER_DMA_APBPERI_SPI2                       (WORLD_CONTROL_BASE + 0x800)
+#define WORLD_CONTROLLER_DMA_APBPERI_SPI3                       (WORLD_CONTROL_BASE + 0x804)
+#define WORLD_CONTROLLER_DMA_APBPERI_UCHI0                      (WORLD_CONTROL_BASE + 0x808)
+#define WORLD_CONTROLLER_DMA_APBPERI_I2S0                       (WORLD_CONTROL_BASE + 0x80C)
+#define WORLD_CONTROLLER_DMA_APBPERI_I2S1                       (WORLD_CONTROL_BASE + 0x810)
+#define WORLD_CONTROLLER_DMA_APBPERI_LCD_CAM                    (WORLD_CONTROL_BASE + 0x814)
+#define WORLD_CONTROLLER_DMA_APBPERI_AES                        (WORLD_CONTROL_BASE + 0x818)
+#define WORLD_CONTROLLER_DMA_APBPERI_SHA                        (WORLD_CONTROL_BASE + 0x81C)
+#define WORLD_CONTROLLER_DMA_APBPERI_ADC_DAC                    (WORLD_CONTROL_BASE + 0x820)
+#define WORLD_CONTROLLER_DMA_APBPERI_USB                        (WORLD_CONTROL_BASE + 0x824)
+#define WORLD_CONTROLLER_DMA_APBPERI_SDIO_HOST                  (WORLD_CONTROL_BASE + 0x828)
+#define WORLD_CONTROLLER_DMA_APBPERI_MAC                        (WORLD_CONTROL_BASE + 0x82C)
+#define WORLD_CONTROLLER_DMA_APBPERI_BACKUP                     (WORLD_CONTROL_BASE + 0x830)
+#define WORLD_CONTROLLER_DMA_APBPERI_SLC                        (WORLD_CONTROL_BASE + 0x834)
+#define WORLD_CONTROLLER_DMA_APBPERI_LC                         (WORLD_CONTROL_BASE + 0x838)
+#define WORLD_CONTROLLER_EDMA_SPI2                              (WORLD_CONTROL_BASE + 0x900)
+#define WORLD_CONTROLLER_EDMA_SPI3                              (WORLD_CONTROL_BASE + 0x904)
+#define WORLD_CONTROLLER_EDMA_UCHI0                             (WORLD_CONTROL_BASE + 0x908)
+#define WORLD_CONTROLLER_EDMA_I2S0                              (WORLD_CONTROL_BASE + 0x90C)
+#define WORLD_CONTROLLER_EDMA_I2S1                              (WORLD_CONTROL_BASE + 0x910)
+#define WORLD_CONTROLLER_EDMA_LCD_CAM                           (WORLD_CONTROL_BASE + 0x914)
+#define WORLD_CONTROLLER_EDMA_AES                               (WORLD_CONTROL_BASE + 0x918)
+#define WORLD_CONTROLLER_EDMA_SHA                               (WORLD_CONTROL_BASE + 0x91C)
+#define WORLD_CONTROLLER_EDMA_ADC_DAC                           (WORLD_CONTROL_BASE + 0x920)
diff --git a/components/soc/esp32s3/include/soc/ext_mem_defs.h b/components/soc/esp32s3/include/soc/ext_mem_defs.h
new file mode 100644
index 0000000000..b26bbe8db9
--- /dev/null
+++ b/components/soc/esp32s3/include/soc/ext_mem_defs.h
@@ -0,0 +1,109 @@
+/*
+ * SPDX-FileCopyrightText: 2020-2021 Espressif Systems (Shanghai) CO LTD
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ */
+#pragma once
+
+#include "esp_bit_defs.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*IRAM0 is connected with Cache IBUS0*/
+#define IRAM0_ADDRESS_LOW               0x40000000
+#define IRAM0_ADDRESS_HIGH              0x44000000
+#define IRAM0_CACHE_ADDRESS_LOW         0x42000000
+#define IRAM0_CACHE_ADDRESS_HIGH        0x44000000
+
+/*DRAM0 is connected with Cache DBUS0*/
+#define DRAM0_ADDRESS_LOW               0x3C000000
+#define DRAM0_ADDRESS_HIGH              0x40000000
+#define DRAM0_CACHE_ADDRESS_LOW         0x3C000000
+#define DRAM0_CACHE_ADDRESS_HIGH        0x3E000000
+#define DRAM0_CACHE_OPERATION_HIGH      DRAM0_CACHE_ADDRESS_HIGH
+#define ESP_CACHE_TEMP_ADDR             0x3C800000
+
+#define BUS_SIZE(bus_name)                 (bus_name##_ADDRESS_HIGH - bus_name##_ADDRESS_LOW)
+#define ADDRESS_IN_BUS(bus_name, vaddr)    ((vaddr) >= bus_name##_ADDRESS_LOW && (vaddr) < bus_name##_ADDRESS_HIGH)
+
+#define ADDRESS_IN_IRAM0(vaddr)            ADDRESS_IN_BUS(IRAM0, vaddr)
+#define ADDRESS_IN_IRAM0_CACHE(vaddr)      ADDRESS_IN_BUS(IRAM0_CACHE, vaddr)
+#define ADDRESS_IN_DRAM0(vaddr)            ADDRESS_IN_BUS(DRAM0, vaddr)
+#define ADDRESS_IN_DRAM0_CACHE(vaddr)      ADDRESS_IN_BUS(DRAM0_CACHE, vaddr)
+
+#define BUS_IRAM0_CACHE_SIZE              BUS_SIZE(IRAM0_CACHE)
+#define BUS_DRAM0_CACHE_SIZE              BUS_SIZE(DRAM0_CACHE)
+
+#define CACHE_IBUS                      0
+#define CACHE_IBUS_MMU_START            0
+#define CACHE_IBUS_MMU_END              0x800
+
+#define CACHE_DBUS                      1
+#define CACHE_DBUS_MMU_START            0
+#define CACHE_DBUS_MMU_END              0x800
+
+//TODO, remove these cache function dependencies
+#define CACHE_IROM_MMU_START            0
+#define CACHE_IROM_MMU_END              Cache_Get_IROM_MMU_End()
+#define CACHE_IROM_MMU_SIZE             (CACHE_IROM_MMU_END - CACHE_IROM_MMU_START)
+
+#define CACHE_DROM_MMU_START            CACHE_IROM_MMU_END
+#define CACHE_DROM_MMU_END              Cache_Get_DROM_MMU_End()
+#define CACHE_DROM_MMU_SIZE             (CACHE_DROM_MMU_END - CACHE_DROM_MMU_START)
+
+#define CACHE_DROM_MMU_MAX_END          0x400
+
+#define ICACHE_MMU_SIZE                 0x800
+#define DCACHE_MMU_SIZE                 0x800
+
+#define MMU_BUS_START(i)                0
+#define MMU_BUS_SIZE(i)                 0x800
+
+#define MMU_INVALID                     BIT(14)
+#define MMU_VALID                       0
+#define MMU_TYPE                        BIT(15)
+#define MMU_ACCESS_FLASH                0
+#define MMU_ACCESS_SPIRAM               BIT(15)
+
+#define CACHE_MAX_SYNC_NUM 0x400000
+#define CACHE_MAX_LOCK_NUM 0x8000
+
+#define FLASH_MMU_TABLE ((volatile uint32_t*) DR_REG_MMU_TABLE)
+#define FLASH_MMU_TABLE_SIZE (ICACHE_MMU_SIZE/sizeof(uint32_t))
+
+/**
+ * MMU entry valid bit mask for mapping value. For an entry:
+ * valid bit + value bits
+ * valid bit is BIT(14), so value bits are 0x3fff
+ */
+#define MMU_VALID_VAL_MASK 0x3fff
+/**
+ * Max MMU available paddr page num.
+ * `MMU_MAX_PADDR_PAGE_NUM * CONFIG_MMU_PAGE_SIZE` means the max paddr address supported by the MMU. e.g.:
+ * 16384 * 64KB, means MMU can support 1GB paddr at most
+ */
+#define MMU_MAX_PADDR_PAGE_NUM    16384
+/**
+ * This is the mask used for mapping. e.g.:
+ * 0x4200_0000 & MMU_VADDR_MASK
+ */
+#define MMU_VADDR_MASK  0x1FFFFFF
+//MMU entry num
+#define MMU_ENTRY_NUM   512
+
+#define CACHE_ICACHE_LOW_SHIFT         0
+#define CACHE_ICACHE_HIGH_SHIFT        2
+#define CACHE_DCACHE_LOW_SHIFT         4
+#define CACHE_DCACHE_HIGH_SHIFT        6
+
+#define CACHE_MEMORY_IBANK0_ADDR        0x40370000
+#define CACHE_MEMORY_IBANK1_ADDR        0x40374000
+
+#define CACHE_MEMORY_DBANK0_ADDR        0x3fcf0000
+#define CACHE_MEMORY_DBANK1_ADDR        0x3fcf8000
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/components/soc/esp32s3/include/soc/memprot_defs.h b/components/soc/esp32s3/include/soc/memprot_defs.h
new file mode 100644
index 0000000000..b500d42eaa
--- /dev/null
+++ b/components/soc/esp32s3/include/soc/memprot_defs.h
@@ -0,0 +1,52 @@
+/*
+ * SPDX-FileCopyrightText: 2020-2022 Espressif Systems (Shanghai) CO LTD
+ *
+ * SPDX-License-Identifier: Apache-2.0
+ */
+
+#pragma once
+
+#include "soc/sensitive_reg.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef union {
+    struct {
+        uint32_t cat0       : 2;
+        uint32_t cat1       : 2;
+        uint32_t cat2       : 2;
+        uint32_t cat3       : 2;
+        uint32_t cat4       : 2;
+        uint32_t cat5       : 2;
+        uint32_t cat6       : 2;
+        uint32_t splitaddr  : 8;
+        uint32_t reserved   : 10;
+    };
+    uint32_t val;
+} constrain_reg_fields_t;
+
+#define I_D_SRAM_SEGMENT_SIZE       0x10000
+#define I_D_SPLIT_LINE_ALIGN        0x100
+#define I_D_SPLIT_LINE_SHIFT        0x8
+#define I_FAULT_ADDR_SHIFT          0x2
+#define D_FAULT_ADDR_SHIFT          0x4
+
+//IRAM0
+#define SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_R  0x1
+#define SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_W  0x2
+#define SENSITIVE_CORE_X_IRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_F  0x4
+
+//DRAM0
+#define SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_R  0x1
+#define SENSITIVE_CORE_X_DRAM0_PMS_CONSTRAIN_SRAM_WORLD_X_W  0x2
+
+//RTC FAST
+#define SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_W  0x1
+#define SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_R  0x2
+#define SENSITIVE_CORE_X_PIF_PMS_CONSTRAIN_RTCFAST_WORLD_X_F  0x4
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/components/soc/esp32s3/include/soc/soc.h b/components/soc/esp32s3/include/soc/soc.h
index b16809779a..a686d8ae22 100644
--- a/components/soc/esp32s3/include/soc/soc.h
+++ b/components/soc/esp32s3/include/soc/soc.h
@@ -108,6 +108,7 @@
 #define DR_REG_EXT_MEM_ENC                      0x600CC000
 
 #define DR_REG_ASSIST_DEBUG_BASE                0x600CE000
+#define DR_REG_WORLD_CONTROLLER_BASE            0x600D0000
 #define DR_REG_WORLD_CNTL_BASE                  0x600D0000
 #define DR_REG_DPORT_END                        0x600D3FFC
 
diff --git a/components/spi_flash/include/esp_partition.h b/components/spi_flash/include/esp_partition.h
index 550bf6b6b2..de4bc9a9bc 100644
--- a/components/spi_flash/include/esp_partition.h
+++ b/components/spi_flash/include/esp_partition.h
@@ -79,6 +79,12 @@ typedef enum {
     ESP_PARTITION_SUBTYPE_APP_OTA_14 = ESP_PARTITION_SUBTYPE_APP_OTA_MIN + 14,//!< OTA partition 14
     ESP_PARTITION_SUBTYPE_APP_OTA_15 = ESP_PARTITION_SUBTYPE_APP_OTA_MIN + 15,//!< OTA partition 15
     ESP_PARTITION_SUBTYPE_APP_OTA_MAX = ESP_PARTITION_SUBTYPE_APP_OTA_MIN + 16,//!< Max subtype of OTA partition
+
+    ESP_PARTITION_SUBTYPE_APP_USER_MIN = 0x40,
+    ESP_PARTITION_SUBTYPE_APP_USER_0 = ESP_PARTITION_SUBTYPE_APP_USER_MIN + 0,
+    ESP_PARTITION_SUBTYPE_APP_USER_1 = ESP_PARTITION_SUBTYPE_APP_USER_MIN + 1,
+    ESP_PARTITION_SUBTYPE_DATA_USER_OTA = 0x50,
+
     ESP_PARTITION_SUBTYPE_APP_TEST = 0x20,                                    //!< Test application partition
 
     ESP_PARTITION_SUBTYPE_DATA_OTA = 0x00,                                    //!< OTA selection partition
diff --git a/tools/idf_monitor_base/gdbhelper.py b/tools/idf_monitor_base/gdbhelper.py
index f32d4fb688..55d7dda1fc 100644
--- a/tools/idf_monitor_base/gdbhelper.py
+++ b/tools/idf_monitor_base/gdbhelper.py
@@ -103,6 +103,11 @@ class GDBHelper:
 
     def process_panic_output(self, panic_output, logger, target):  # type: (bytes, Logger, str) -> None
         panic_output_file = None
+        user_app = os.path.dirname(self.elf_file) + '/user_app/user_app.elf'
+        if os.path.isfile(user_app):
+            user_symbols = 'add-symbol-file %s' % user_app
+        else:
+            user_symbols = ''
         try:
             # On Windows, the temporary file can't be read unless it is closed.
             # Set delete=False and delete the file manually later.
@@ -112,6 +117,7 @@ class GDBHelper:
             cmd = [self.toolchain_prefix + 'gdb',
                    '--batch', '-n',
                    self.elf_file,
+                   '-ex', user_symbols,
                    '-ex', "target remote | \"{python}\" \"{script}\" --target {target} \"{output_file}\""
                        .format(python=sys.executable,
                                script=PANIC_OUTPUT_DECODE_SCRIPT,
